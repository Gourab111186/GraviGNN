{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraviGNN: Gravity Inversion using Graph Neural Networks\n",
    "\n",
    "This notebook provides evaluation code for the **GraviGNN** model used for gravity anomaly inversion with 5% Gaussian Noise.\n",
    "\n",
    "### Contents\n",
    "- Import Libraries\n",
    "- Hyperparameter Setup\n",
    "- Model Architecture\n",
    "- Loss Functions\n",
    "- Dataset Loading\n",
    "- Model Training\n",
    "- Evaluation on Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "This section imports all required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as colors\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "plt.rc('font',family='Times New Roman', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training Hyperparameters\n",
    "\n",
    "Defines core training parameters including:\n",
    "- Number of epochs\n",
    "- Learning rate\n",
    "- Early stopping patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep network parameters\n",
    "patience = 20\n",
    "epochs = 150\n",
    "tra_num = 20000\n",
    "val_num = 2000\n",
    "part_num = 100\n",
    "category = 6\n",
    "batch_size = 16\n",
    "num_cell = 32\n",
    "learning_rate = 4e-4\n",
    "threshold = 1e-4\n",
    "realdata_num = 1\n",
    "start_fm = 32\n",
    "syn_num = part_num*category\n",
    "total_num = tra_num + val_num\n",
    "\n",
    "\n",
    "# Physical parameters\n",
    "density = 1000\n",
    "\n",
    "# # Ablation\n",
    "# noise_levels = [0.02, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Architecture\n",
    "\n",
    "Defines the neural network components used in GraviGNN.\n",
    "This includes:\n",
    "- Double convolution blocks\n",
    "- Encoder-decoder structure\n",
    "- Final prediction layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Define basic modules\n",
    "#############################\n",
    "\n",
    "# Standard double convolution block (used for local feature extraction)\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.ELU = nn.ELU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ELU(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "##############################################\n",
    "# Graph Convolution with Multi-Head Updates\n",
    "##############################################\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph convolution that:\n",
    "      1. Computes K-nearest neighbors based on Euclidean distance.\n",
    "      2. Aggregates neighbor features via an elementwise maximum.\n",
    "      3. Concatenates the original node feature with the aggregated neighbor feature.\n",
    "      4. Applies multi-head linear updates.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, k=8):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.k = k\n",
    "        assert out_dim % num_heads == 0, \"out_dim must be divisible by num_heads\"\n",
    "        self.head_dim = out_dim // num_heads\n",
    "        # Create a separate linear layer for each head.\n",
    "        self.linears = nn.ModuleList([nn.Linear(2 * in_dim, self.head_dim) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, N, D)\n",
    "        B, N, D = x.shape\n",
    "\n",
    "        # Compute pairwise Euclidean distances: shape (B, N, N)\n",
    "        dist = torch.cdist(x, x, p=2)\n",
    "        # Mask self-distance by setting diagonal entries to infinity\n",
    "        diag = torch.eye(N, device=x.device).bool().unsqueeze(0)\n",
    "        dist.masked_fill_(diag, float('inf'))\n",
    "        # Select effective k to avoid selecting more neighbors than available\n",
    "        effective_k = self.k if self.k < N else N - 1\n",
    "        # Get indices of k nearest neighbors (smallest distances)\n",
    "        knn_indices = torch.topk(-dist, k=effective_k, dim=-1).indices  # shape: (B, N, effective_k)\n",
    "\n",
    "        # Gather neighbor features using advanced indexing\n",
    "        batch_indices = torch.arange(B, device=x.device).view(B, 1, 1).expand(B, N, effective_k)\n",
    "        neighbors = x[batch_indices, knn_indices]  # shape: (B, N, effective_k, D)\n",
    "\n",
    "        # Aggregate neighbors with elementwise maximum across the k dimension\n",
    "        agg, _ = torch.max(neighbors, dim=2)  # shape: (B, N, D)\n",
    "\n",
    "        # Concatenate the original feature with the aggregated neighbor feature\n",
    "        concat_feat = torch.cat([x, agg], dim=-1)  # (B, N, 2*D)\n",
    "\n",
    "        # Multi-head update: apply a separate linear projection per head and concatenate\n",
    "        head_outputs = []\n",
    "        for linear in self.linears:\n",
    "            head_outputs.append(linear(concat_feat))  # each: (B, N, head_dim)\n",
    "        out = torch.cat(head_outputs, dim=-1)  # (B, N, out_dim)\n",
    "        return out\n",
    "\n",
    "##############################################\n",
    "# ViG Block: Graph-level processing with enhancement\n",
    "##############################################\n",
    "\n",
    "class ViGBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ViG block that applies:\n",
    "      - A graph convolution (with pre- and post- linear projections and nonlinear activations)\n",
    "      - A feed-forward network (FFN) to further refine node features.\n",
    "      \n",
    "    The block follows:\n",
    "         Y = (GraphConv(X * W_in)) * W_out + X\n",
    "         Z = FFN(Y) + Y\n",
    "    with normalization (LayerNorm) and dropout to help prevent over-smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, k=8, ff_hidden_dim=None, dropout=0.1):\n",
    "        super(ViGBlock, self).__init__()\n",
    "        ff_hidden_dim = ff_hidden_dim or in_dim * 2\n",
    "        self.proj_in = nn.Linear(in_dim, in_dim)\n",
    "        self.graph_conv = GraphConv(in_dim, out_dim, num_heads=num_heads, k=k)\n",
    "        self.proj_out = nn.Linear(out_dim, out_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(out_dim)\n",
    "        # Feed-forward network (FFN)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_dim, ff_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_dim, out_dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, N, D)\n",
    "        x_proj = self.proj_in(x)  # project into same domain: (B, N, D)\n",
    "        gc = self.graph_conv(x_proj)  # graph convolution: (B, N, out_dim)\n",
    "        gc = self.proj_out(gc)\n",
    "        gc = self.activation(gc)\n",
    "        gc = self.dropout(gc)\n",
    "        y = x + gc  # residual connection\n",
    "        y = self.norm1(y)\n",
    "        # FFN to further refine features\n",
    "        ffn_out = self.ffn(y)\n",
    "        ffn_out = self.dropout(ffn_out)\n",
    "        out = y + ffn_out  # residual connection\n",
    "        out = self.norm2(out)\n",
    "        return out\n",
    "\n",
    "##############################################\n",
    "# ViG-based UNet Architecture (Pyramid Architecture)\n",
    "##############################################\n",
    "\n",
    "class ViGUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    This network combines CNN-based patch processing with graph neural network modules.\n",
    "    \n",
    "    Unified Flow Summary:\n",
    "       1. Input Processing:\n",
    "          - An image is divided into patches.\n",
    "          - Each patch is converted into a feature vector to form matrix X.\n",
    "       2. Graph Construction:\n",
    "          - A graph G is built where each node represents a patch.\n",
    "          - Edges are created by connecting each node to its K nearest neighbors.\n",
    "       3. Graph Convolution and Multi-Head Updates:\n",
    "          - Graph convolution aggregates neighbor information via a max-relative function.\n",
    "          - Features are updated via a multi-head mechanism.\n",
    "       4. ViG Block Enhancement:\n",
    "          - A Grapher module (ViGBlock) uses pre- and post- projections, nonlinear activations, and residual connections.\n",
    "          - An FFN further refines node features.\n",
    "       5. Network Architectures:\n",
    "          - The ViG blocks are stacked to form a UNet-like encoder-decoder (pyramid) architecture.\n",
    "    \n",
    "    This complete flow leverages graph neural network principles with modern network design strategies.\n",
    "    \"\"\"\n",
    "    def __init__(self, start_fm=32, num_heads=4, ff_hidden_dim=None, dropout=0.1, k=8):\n",
    "        super(ViGUNet, self).__init__()\n",
    "        self.start_fm = start_fm\n",
    "\n",
    "        # Encoder Stage 1\n",
    "        self.enc1_conv = double_conv(1, start_fm)\n",
    "        self.enc1_vig = ViGBlock(start_fm, start_fm, num_heads=num_heads, k=k, dropout=dropout)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Encoder Stage 2\n",
    "        self.enc2_conv = double_conv(start_fm, start_fm * 2)\n",
    "        self.enc2_vig = ViGBlock(start_fm * 2, start_fm * 2, num_heads=num_heads, k=k, dropout=dropout)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Encoder Stage 3\n",
    "        self.enc3_conv = double_conv(start_fm * 2, start_fm * 4)\n",
    "        self.enc3_vig = ViGBlock(start_fm * 4, start_fm * 4, num_heads=num_heads, k=k, dropout=dropout)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Encoder Stage 4\n",
    "        self.enc4_conv = double_conv(start_fm * 4, start_fm * 8)\n",
    "        self.enc4_vig = ViGBlock(start_fm * 8, start_fm * 8, num_heads=num_heads, k=k, dropout=dropout)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck_conv = double_conv(start_fm * 8, start_fm * 16)\n",
    "        self.bottleneck_vig = ViGBlock(start_fm * 16, start_fm * 16, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        # Decoder Stage 4\n",
    "        self.up4 = nn.ConvTranspose2d(start_fm * 16, start_fm * 8, kernel_size=2, stride=2)\n",
    "        self.dec4_conv = double_conv(start_fm * 16, start_fm * 8)\n",
    "        self.dec4_vig = ViGBlock(start_fm * 8, start_fm * 8, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        # Decoder Stage 3\n",
    "        self.up3 = nn.ConvTranspose2d(start_fm * 8, start_fm * 4, kernel_size=2, stride=2)\n",
    "        self.dec3_conv = double_conv(start_fm * 8, start_fm * 4)\n",
    "        self.dec3_vig = ViGBlock(start_fm * 4, start_fm * 4, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        # Decoder Stage 2\n",
    "        self.up2 = nn.ConvTranspose2d(start_fm * 4, start_fm * 2, kernel_size=2, stride=2)\n",
    "        self.dec2_conv = double_conv(start_fm * 4, start_fm * 2)\n",
    "        self.dec2_vig = ViGBlock(start_fm * 2, start_fm * 2, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        # Decoder Stage 1\n",
    "        self.up1 = nn.ConvTranspose2d(start_fm * 2, start_fm, kernel_size=2, stride=2)\n",
    "        self.dec1_conv = double_conv(start_fm * 2, start_fm)\n",
    "        self.dec1_vig = ViGBlock(start_fm, start_fm, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(start_fm, 16, kernel_size=1)\n",
    "        self.final_bn = nn.BatchNorm2d(16)\n",
    "        self.final_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Encoder Stage 1\n",
    "        enc1 = self.enc1_conv(inputs)  # (B, start_fm, H, W)\n",
    "        B, C, H, W = enc1.shape\n",
    "        enc1_flat = enc1.view(B, C, H * W).permute(0, 2, 1)  # (B, N, C)\n",
    "        enc1_vig = self.enc1_vig(enc1_flat)\n",
    "        enc1 = enc1_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "        pool1 = self.pool1(enc1)\n",
    "\n",
    "        # Encoder Stage 2\n",
    "        enc2 = self.enc2_conv(pool1)\n",
    "        B, C, H, W = enc2.shape\n",
    "        enc2_flat = enc2.view(B, C, H * W).permute(0, 2, 1)\n",
    "        enc2_vig = self.enc2_vig(enc2_flat)\n",
    "        enc2 = enc2_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "        pool2 = self.pool2(enc2)\n",
    "\n",
    "        # Encoder Stage 3\n",
    "        enc3 = self.enc3_conv(pool2)\n",
    "        B, C, H, W = enc3.shape\n",
    "        enc3_flat = enc3.view(B, C, H * W).permute(0, 2, 1)\n",
    "        enc3_vig = self.enc3_vig(enc3_flat)\n",
    "        enc3 = enc3_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "        pool3 = self.pool3(enc3)\n",
    "\n",
    "        # Encoder Stage 4\n",
    "        enc4 = self.enc4_conv(pool3)\n",
    "        B, C, H, W = enc4.shape\n",
    "        enc4_flat = enc4.view(B, C, H * W).permute(0, 2, 1)\n",
    "        enc4_vig = self.enc4_vig(enc4_flat)\n",
    "        enc4 = enc4_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "        pool4 = self.pool4(enc4)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck_conv(pool4)\n",
    "        B, C, H, W = bottleneck.shape\n",
    "        bottleneck_flat = bottleneck.view(B, C, H * W).permute(0, 2, 1)\n",
    "        bottleneck_vig = self.bottleneck_vig(bottleneck_flat)\n",
    "        bottleneck = bottleneck_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Decoder Stage 4\n",
    "        up4 = self.up4(bottleneck)\n",
    "        cat4 = torch.cat([up4, enc4], dim=1)\n",
    "        dec4 = self.dec4_conv(cat4)\n",
    "        B, C, H, W = dec4.shape\n",
    "        dec4_flat = dec4.view(B, C, H * W).permute(0, 2, 1)\n",
    "        dec4_vig = self.dec4_vig(dec4_flat)\n",
    "        dec4 = dec4_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Decoder Stage 3\n",
    "        up3 = self.up3(dec4)\n",
    "        cat3 = torch.cat([up3, enc3], dim=1)\n",
    "        dec3 = self.dec3_conv(cat3)\n",
    "        B, C, H, W = dec3.shape\n",
    "        dec3_flat = dec3.view(B, C, H * W).permute(0, 2, 1)\n",
    "        dec3_vig = self.dec3_vig(dec3_flat)\n",
    "        dec3 = dec3_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Decoder Stage 2\n",
    "        up2 = self.up2(dec3)\n",
    "        cat2 = torch.cat([up2, enc2], dim=1)\n",
    "        dec2 = self.dec2_conv(cat2)\n",
    "        B, C, H, W = dec2.shape\n",
    "        dec2_flat = dec2.view(B, C, H * W).permute(0, 2, 1)\n",
    "        dec2_vig = self.dec2_vig(dec2_flat)\n",
    "        dec2 = dec2_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Decoder Stage 1\n",
    "        up1 = self.up1(dec2)\n",
    "        cat1 = torch.cat([up1, enc1], dim=1)\n",
    "        dec1 = self.dec1_conv(cat1)\n",
    "        B, C, H, W = dec1.shape\n",
    "        dec1_flat = dec1.view(B, C, H * W).permute(0, 2, 1)\n",
    "        dec1_vig = self.dec1_vig(dec1_flat)\n",
    "        dec1 = dec1_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        out = self.final_conv(dec1)\n",
    "        out = self.final_bn(out)\n",
    "        out = self.final_act(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "Implements Dice loss for segmentation-based density reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dice(pred, target):\n",
    "    smooth = 1\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.reshape(num, -1)\n",
    "    m2 = target.reshape(num, -1)\n",
    "    intersection = m1 * m2\n",
    "    loss = (2. * intersection.sum(1) + smooth) / ((m1 * m1).sum(1) + (m2 * m2).sum(1) + smooth)\n",
    "    return loss.sum() / num\n",
    "\n",
    "def my_loss(pre_y, tru_y):\n",
    "    loss = 1 - dice(pre_y, tru_y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading and Preprocessing\n",
    "\n",
    "Loads gravity anomaly data and corresponding density models.\n",
    "Prepares PyTorch Dataset and DataLoader objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folders\n",
    "dataFile = './data/tra&val/data{}.mat'\n",
    "syn_dataFile = './data/syn/data{}.mat'\n",
    "\n",
    "# For creating the forward response\n",
    "with h5py.File(name='./G.mat', mode='r') as f:G = torch.Tensor(np.nan_to_num(f['G'][:])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "Implements adding noise 5% Gaussian, forward pass, loss computation, backpropagation, and model saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1, 32, 32) :: (20000, 16, 32, 32)\n",
      "(2000, 1, 32, 32) :: (2000, 16, 32, 32)\n",
      "(600, 1, 32, 32) :: (600, 16, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# total_num, dataFile, density, num_cell, tra_num, val_num, syn_num, syn_dataFile, noise_levels\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(total_num):\n",
    "    data = h5py.File(dataFile.format(i), 'r')  # Open each file\n",
    "    m = data['m'][0] / density                  # Scale m by density\n",
    "    d = data['d'][0]                            # Get d data\n",
    "    d = np.nan_to_num(d)                        # Replace NaN values with 0\n",
    "    x.append(d.reshape(1, num_cell, num_cell))  # Reshape and append to x\n",
    "    y.append(m.reshape(16, num_cell, num_cell)) # Reshape and append to y\n",
    "\n",
    "syn_x = []\n",
    "syn_y = []\n",
    "for i in range(syn_num):\n",
    "    data = h5py.File(syn_dataFile.format(i), 'r')  # Open each synthetic data file\n",
    "    m = data['m'][0] / density                    # Scale m by density\n",
    "    d = data['d'][0]                              # Get d data\n",
    "    d = np.nan_to_num(d)                          # Replace NaN values with 0\n",
    "    syn_x.append(d.reshape(1, num_cell, num_cell)) # Reshape and append to syn_x\n",
    "    syn_y.append(m.reshape(16, num_cell, num_cell))# Reshape and append to syn_y\n",
    "\n",
    "# Define the noise level (as requested, 0.02)\n",
    "noise_level = 0.05\n",
    "\n",
    "# Add noise to 'x' (but not to 'y')\n",
    "for i in range(len(x)):\n",
    "    d = x[i]  # Data from the 'x' list\n",
    "    noise_d = d + np.array(noise_level * np.max(d)) * np.random.normal(0, 1, d.shape)  # Add noise\n",
    "    noise_d = np.where(noise_d > 0, noise_d, 0)  # Ensure no negative values\n",
    "    x[i] = noise_d  # Replace original data with noisy data\n",
    "\n",
    "# Split data into training and validation\n",
    "tra_x = x[:tra_num]\n",
    "tra_y = y[:tra_num]\n",
    "val_x = x[-val_num:]\n",
    "val_y = y[-val_num:]\n",
    "\n",
    "\n",
    "# Add noise to 'syn_x'\n",
    "for i in range(len(syn_x)):\n",
    "    d = syn_x[i]  # Data from the 'syn_x' list\n",
    "    noise_d = d + np.array(noise_level * np.max(d)) * np.random.normal(0, 1, d.shape)  # Add noise\n",
    "    noise_d = np.where(noise_d > 0, noise_d, 0)  # Ensure no negative values\n",
    "    syn_x[i] = noise_d  # Replace original data with noisy data\n",
    "\n",
    "# Print the shapes of the datasets after modification\n",
    "print(np.shape(tra_x), \"::\", np.shape(tra_y))\n",
    "print(np.shape(val_x), \"::\", np.shape(val_y))\n",
    "print(np.shape(syn_x), \"::\", np.shape(syn_y))\n",
    "\n",
    "# Indices for training, validation, and synthetic data\n",
    "tra_idxs = list(range(len(tra_x)))  # Training data indices\n",
    "val_idxs = list(range(len(val_x)))  # Validation data indices\n",
    "# np.random.shuffle(tra_idxs)  # Shuffle training indices (optional)\n",
    "# np.random.shuffle(val_idxs)  # Shuffle validation indices (optional)\n",
    "syn_idxs = list(range(len(syn_x)))  # Synthetic data indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, train=True, masks=None):\n",
    "        self.train = train\n",
    "        self.images = images\n",
    "        if self.train:\n",
    "            self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = None\n",
    "        if self.train:\n",
    "            mask = self.masks[idx]\n",
    "        return (image, mask)\n",
    "\n",
    "\n",
    "tra = Dataset(np.array(tra_x).astype(np.float32)[tra_idxs], train=True,\n",
    "              masks=np.array(tra_y).astype(np.float32)[tra_idxs])\n",
    "val = Dataset(np.array(val_x).astype(np.float32)[val_idxs], train=True,\n",
    "              masks=np.array(val_y).astype(np.float32)[val_idxs])\n",
    "syn = Dataset(np.array(syn_x).astype(np.float32)[syn_idxs], train=True,\n",
    "              masks=np.array(syn_y).astype(np.float32)[syn_idxs])\n",
    "\n",
    "tra_loader = torch.utils.data.DataLoader(dataset=tra, batch_size=batch_size, shuffle=False, pin_memory=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batch_size, shuffle=False, pin_memory=False)\n",
    "syn_loader = torch.utils.data.DataLoader(dataset=syn, batch_size=batch_size, shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             320\n",
      "               ELU-2           [-1, 32, 32, 32]               0\n",
      "            Conv2d-3           [-1, 32, 32, 32]           9,248\n",
      "       double_conv-4           [-1, 32, 32, 32]               0\n",
      "            Linear-5             [-1, 1024, 32]           1,056\n",
      "            Linear-6              [-1, 1024, 8]             520\n",
      "            Linear-7              [-1, 1024, 8]             520\n",
      "            Linear-8              [-1, 1024, 8]             520\n",
      "            Linear-9              [-1, 1024, 8]             520\n",
      "        GraphConv-10             [-1, 1024, 32]               0\n",
      "           Linear-11             [-1, 1024, 32]           1,056\n",
      "             ReLU-12             [-1, 1024, 32]               0\n",
      "          Dropout-13             [-1, 1024, 32]               0\n",
      "        LayerNorm-14             [-1, 1024, 32]              64\n",
      "           Linear-15             [-1, 1024, 64]           2,112\n",
      "             ReLU-16             [-1, 1024, 64]               0\n",
      "           Linear-17             [-1, 1024, 32]           2,080\n",
      "          Dropout-18             [-1, 1024, 32]               0\n",
      "        LayerNorm-19             [-1, 1024, 32]              64\n",
      "         ViGBlock-20             [-1, 1024, 32]               0\n",
      "        MaxPool2d-21           [-1, 32, 16, 16]               0\n",
      "           Conv2d-22           [-1, 64, 16, 16]          18,496\n",
      "              ELU-23           [-1, 64, 16, 16]               0\n",
      "           Conv2d-24           [-1, 64, 16, 16]          36,928\n",
      "      double_conv-25           [-1, 64, 16, 16]               0\n",
      "           Linear-26              [-1, 256, 64]           4,160\n",
      "           Linear-27              [-1, 256, 16]           2,064\n",
      "           Linear-28              [-1, 256, 16]           2,064\n",
      "           Linear-29              [-1, 256, 16]           2,064\n",
      "           Linear-30              [-1, 256, 16]           2,064\n",
      "        GraphConv-31              [-1, 256, 64]               0\n",
      "           Linear-32              [-1, 256, 64]           4,160\n",
      "             ReLU-33              [-1, 256, 64]               0\n",
      "          Dropout-34              [-1, 256, 64]               0\n",
      "        LayerNorm-35              [-1, 256, 64]             128\n",
      "           Linear-36             [-1, 256, 128]           8,320\n",
      "             ReLU-37             [-1, 256, 128]               0\n",
      "           Linear-38              [-1, 256, 64]           8,256\n",
      "          Dropout-39              [-1, 256, 64]               0\n",
      "        LayerNorm-40              [-1, 256, 64]             128\n",
      "         ViGBlock-41              [-1, 256, 64]               0\n",
      "        MaxPool2d-42             [-1, 64, 8, 8]               0\n",
      "           Conv2d-43            [-1, 128, 8, 8]          73,856\n",
      "              ELU-44            [-1, 128, 8, 8]               0\n",
      "           Conv2d-45            [-1, 128, 8, 8]         147,584\n",
      "      double_conv-46            [-1, 128, 8, 8]               0\n",
      "           Linear-47              [-1, 64, 128]          16,512\n",
      "           Linear-48               [-1, 64, 32]           8,224\n",
      "           Linear-49               [-1, 64, 32]           8,224\n",
      "           Linear-50               [-1, 64, 32]           8,224\n",
      "           Linear-51               [-1, 64, 32]           8,224\n",
      "        GraphConv-52              [-1, 64, 128]               0\n",
      "           Linear-53              [-1, 64, 128]          16,512\n",
      "             ReLU-54              [-1, 64, 128]               0\n",
      "          Dropout-55              [-1, 64, 128]               0\n",
      "        LayerNorm-56              [-1, 64, 128]             256\n",
      "           Linear-57              [-1, 64, 256]          33,024\n",
      "             ReLU-58              [-1, 64, 256]               0\n",
      "           Linear-59              [-1, 64, 128]          32,896\n",
      "          Dropout-60              [-1, 64, 128]               0\n",
      "        LayerNorm-61              [-1, 64, 128]             256\n",
      "         ViGBlock-62              [-1, 64, 128]               0\n",
      "        MaxPool2d-63            [-1, 128, 4, 4]               0\n",
      "           Conv2d-64            [-1, 256, 4, 4]         295,168\n",
      "              ELU-65            [-1, 256, 4, 4]               0\n",
      "           Conv2d-66            [-1, 256, 4, 4]         590,080\n",
      "      double_conv-67            [-1, 256, 4, 4]               0\n",
      "           Linear-68              [-1, 16, 256]          65,792\n",
      "           Linear-69               [-1, 16, 64]          32,832\n",
      "           Linear-70               [-1, 16, 64]          32,832\n",
      "           Linear-71               [-1, 16, 64]          32,832\n",
      "           Linear-72               [-1, 16, 64]          32,832\n",
      "        GraphConv-73              [-1, 16, 256]               0\n",
      "           Linear-74              [-1, 16, 256]          65,792\n",
      "             ReLU-75              [-1, 16, 256]               0\n",
      "          Dropout-76              [-1, 16, 256]               0\n",
      "        LayerNorm-77              [-1, 16, 256]             512\n",
      "           Linear-78              [-1, 16, 512]         131,584\n",
      "             ReLU-79              [-1, 16, 512]               0\n",
      "           Linear-80              [-1, 16, 256]         131,328\n",
      "          Dropout-81              [-1, 16, 256]               0\n",
      "        LayerNorm-82              [-1, 16, 256]             512\n",
      "         ViGBlock-83              [-1, 16, 256]               0\n",
      "        MaxPool2d-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85            [-1, 512, 2, 2]       1,180,160\n",
      "              ELU-86            [-1, 512, 2, 2]               0\n",
      "           Conv2d-87            [-1, 512, 2, 2]       2,359,808\n",
      "      double_conv-88            [-1, 512, 2, 2]               0\n",
      "           Linear-89               [-1, 4, 512]         262,656\n",
      "           Linear-90               [-1, 4, 128]         131,200\n",
      "           Linear-91               [-1, 4, 128]         131,200\n",
      "           Linear-92               [-1, 4, 128]         131,200\n",
      "           Linear-93               [-1, 4, 128]         131,200\n",
      "        GraphConv-94               [-1, 4, 512]               0\n",
      "           Linear-95               [-1, 4, 512]         262,656\n",
      "             ReLU-96               [-1, 4, 512]               0\n",
      "          Dropout-97               [-1, 4, 512]               0\n",
      "        LayerNorm-98               [-1, 4, 512]           1,024\n",
      "           Linear-99              [-1, 4, 1024]         525,312\n",
      "            ReLU-100              [-1, 4, 1024]               0\n",
      "          Linear-101               [-1, 4, 512]         524,800\n",
      "         Dropout-102               [-1, 4, 512]               0\n",
      "       LayerNorm-103               [-1, 4, 512]           1,024\n",
      "        ViGBlock-104               [-1, 4, 512]               0\n",
      " ConvTranspose2d-105            [-1, 256, 4, 4]         524,544\n",
      "          Conv2d-106            [-1, 256, 4, 4]       1,179,904\n",
      "             ELU-107            [-1, 256, 4, 4]               0\n",
      "          Conv2d-108            [-1, 256, 4, 4]         590,080\n",
      "     double_conv-109            [-1, 256, 4, 4]               0\n",
      "          Linear-110              [-1, 16, 256]          65,792\n",
      "          Linear-111               [-1, 16, 64]          32,832\n",
      "          Linear-112               [-1, 16, 64]          32,832\n",
      "          Linear-113               [-1, 16, 64]          32,832\n",
      "          Linear-114               [-1, 16, 64]          32,832\n",
      "       GraphConv-115              [-1, 16, 256]               0\n",
      "          Linear-116              [-1, 16, 256]          65,792\n",
      "            ReLU-117              [-1, 16, 256]               0\n",
      "         Dropout-118              [-1, 16, 256]               0\n",
      "       LayerNorm-119              [-1, 16, 256]             512\n",
      "          Linear-120              [-1, 16, 512]         131,584\n",
      "            ReLU-121              [-1, 16, 512]               0\n",
      "          Linear-122              [-1, 16, 256]         131,328\n",
      "         Dropout-123              [-1, 16, 256]               0\n",
      "       LayerNorm-124              [-1, 16, 256]             512\n",
      "        ViGBlock-125              [-1, 16, 256]               0\n",
      " ConvTranspose2d-126            [-1, 128, 8, 8]         131,200\n",
      "          Conv2d-127            [-1, 128, 8, 8]         295,040\n",
      "             ELU-128            [-1, 128, 8, 8]               0\n",
      "          Conv2d-129            [-1, 128, 8, 8]         147,584\n",
      "     double_conv-130            [-1, 128, 8, 8]               0\n",
      "          Linear-131              [-1, 64, 128]          16,512\n",
      "          Linear-132               [-1, 64, 32]           8,224\n",
      "          Linear-133               [-1, 64, 32]           8,224\n",
      "          Linear-134               [-1, 64, 32]           8,224\n",
      "          Linear-135               [-1, 64, 32]           8,224\n",
      "       GraphConv-136              [-1, 64, 128]               0\n",
      "          Linear-137              [-1, 64, 128]          16,512\n",
      "            ReLU-138              [-1, 64, 128]               0\n",
      "         Dropout-139              [-1, 64, 128]               0\n",
      "       LayerNorm-140              [-1, 64, 128]             256\n",
      "          Linear-141              [-1, 64, 256]          33,024\n",
      "            ReLU-142              [-1, 64, 256]               0\n",
      "          Linear-143              [-1, 64, 128]          32,896\n",
      "         Dropout-144              [-1, 64, 128]               0\n",
      "       LayerNorm-145              [-1, 64, 128]             256\n",
      "        ViGBlock-146              [-1, 64, 128]               0\n",
      " ConvTranspose2d-147           [-1, 64, 16, 16]          32,832\n",
      "          Conv2d-148           [-1, 64, 16, 16]          73,792\n",
      "             ELU-149           [-1, 64, 16, 16]               0\n",
      "          Conv2d-150           [-1, 64, 16, 16]          36,928\n",
      "     double_conv-151           [-1, 64, 16, 16]               0\n",
      "          Linear-152              [-1, 256, 64]           4,160\n",
      "          Linear-153              [-1, 256, 16]           2,064\n",
      "          Linear-154              [-1, 256, 16]           2,064\n",
      "          Linear-155              [-1, 256, 16]           2,064\n",
      "          Linear-156              [-1, 256, 16]           2,064\n",
      "       GraphConv-157              [-1, 256, 64]               0\n",
      "          Linear-158              [-1, 256, 64]           4,160\n",
      "            ReLU-159              [-1, 256, 64]               0\n",
      "         Dropout-160              [-1, 256, 64]               0\n",
      "       LayerNorm-161              [-1, 256, 64]             128\n",
      "          Linear-162             [-1, 256, 128]           8,320\n",
      "            ReLU-163             [-1, 256, 128]               0\n",
      "          Linear-164              [-1, 256, 64]           8,256\n",
      "         Dropout-165              [-1, 256, 64]               0\n",
      "       LayerNorm-166              [-1, 256, 64]             128\n",
      "        ViGBlock-167              [-1, 256, 64]               0\n",
      " ConvTranspose2d-168           [-1, 32, 32, 32]           8,224\n",
      "          Conv2d-169           [-1, 32, 32, 32]          18,464\n",
      "             ELU-170           [-1, 32, 32, 32]               0\n",
      "          Conv2d-171           [-1, 32, 32, 32]           9,248\n",
      "     double_conv-172           [-1, 32, 32, 32]               0\n",
      "          Linear-173             [-1, 1024, 32]           1,056\n",
      "          Linear-174              [-1, 1024, 8]             520\n",
      "          Linear-175              [-1, 1024, 8]             520\n",
      "          Linear-176              [-1, 1024, 8]             520\n",
      "          Linear-177              [-1, 1024, 8]             520\n",
      "       GraphConv-178             [-1, 1024, 32]               0\n",
      "          Linear-179             [-1, 1024, 32]           1,056\n",
      "            ReLU-180             [-1, 1024, 32]               0\n",
      "         Dropout-181             [-1, 1024, 32]               0\n",
      "       LayerNorm-182             [-1, 1024, 32]              64\n",
      "          Linear-183             [-1, 1024, 64]           2,112\n",
      "            ReLU-184             [-1, 1024, 64]               0\n",
      "          Linear-185             [-1, 1024, 32]           2,080\n",
      "         Dropout-186             [-1, 1024, 32]               0\n",
      "       LayerNorm-187             [-1, 1024, 32]              64\n",
      "        ViGBlock-188             [-1, 1024, 32]               0\n",
      "          Conv2d-189           [-1, 16, 32, 32]             528\n",
      "     BatchNorm2d-190           [-1, 16, 32, 32]              32\n",
      "         Sigmoid-191           [-1, 16, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 11,264,560\n",
      "Trainable params: 11,264,560\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 19.07\n",
      "Params size (MB): 42.97\n",
      "Estimated Total Size (MB): 62.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = ViGUNet(start_fm=32, num_heads=4, dropout=0.3, k=8)\n",
    "model.cuda()\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Summarize the model with a sample input size (1, 32, 32)\n",
    "summary(model, input_size=(1, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation, and Testing Loop\n",
    "\n",
    "This block performs the complete model training procedure:\n",
    "\n",
    "- **Training phase:**  \n",
    "  The model is set to training mode, performs forward propagation on training data, computes loss, backpropagates gradients, and updates parameters.\n",
    "\n",
    "- **Validation phase:**  \n",
    "  The model switches to evaluation mode. Validation loss is computed without gradient updates. Early stopping is checked based on validation loss stability.\n",
    "\n",
    "- **Synthetic test phase:**  \n",
    "  The model is evaluated on synthetic geological models to assess generalization performance.\n",
    "\n",
    "- **Checkpointing:**  \n",
    "  Model weights are saved at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at the end of epoch 0.\n",
      "Epoch: 1. Tra Loss: 0.8069. Val Loss: 0.7475. Syn Loss: 0.7307\n",
      "Model saved at the end of epoch 1.\n",
      "Epoch: 2. Tra Loss: 0.6582. Val Loss: 0.6093. Syn Loss: 0.4957\n",
      "Model saved at the end of epoch 2.\n",
      "Epoch: 3. Tra Loss: 0.5728. Val Loss: 0.5013. Syn Loss: 0.3684\n",
      "Model saved at the end of epoch 3.\n",
      "Epoch: 4. Tra Loss: 0.5120. Val Loss: 0.4670. Syn Loss: 0.4122\n",
      "Model saved at the end of epoch 4.\n",
      "Epoch: 5. Tra Loss: 0.4474. Val Loss: 0.4231. Syn Loss: 0.3616\n",
      "Model saved at the end of epoch 5.\n",
      "Epoch: 6. Tra Loss: 0.4148. Val Loss: 0.3992. Syn Loss: 0.3324\n",
      "Model saved at the end of epoch 6.\n",
      "Epoch: 7. Tra Loss: 0.3970. Val Loss: 0.3851. Syn Loss: 0.3144\n",
      "Model saved at the end of epoch 7.\n",
      "Epoch: 8. Tra Loss: 0.3871. Val Loss: 0.3787. Syn Loss: 0.3089\n",
      "Model saved at the end of epoch 8.\n",
      "Epoch: 9. Tra Loss: 0.3809. Val Loss: 0.3772. Syn Loss: 0.3181\n",
      "Model saved at the end of epoch 9.\n",
      "Epoch: 10. Tra Loss: 0.3769. Val Loss: 0.3713. Syn Loss: 0.3116\n",
      "Model saved at the end of epoch 10.\n",
      "Epoch: 11. Tra Loss: 0.3746. Val Loss: 0.3778. Syn Loss: 0.3252\n",
      "Model saved at the end of epoch 11.\n",
      "Epoch: 12. Tra Loss: 0.3719. Val Loss: 0.3761. Syn Loss: 0.3205\n",
      "Model saved at the end of epoch 12.\n",
      "Epoch: 13. Tra Loss: 0.3699. Val Loss: 0.3738. Syn Loss: 0.3111\n",
      "Model saved at the end of epoch 13.\n",
      "Epoch: 14. Tra Loss: 0.3694. Val Loss: 0.3743. Syn Loss: 0.3214\n",
      "Model saved at the end of epoch 14.\n",
      "Epoch: 15. Tra Loss: 0.3676. Val Loss: 0.4677. Syn Loss: 0.4074\n",
      "Model saved at the end of epoch 15.\n",
      "Epoch: 16. Tra Loss: 0.3695. Val Loss: 0.3848. Syn Loss: 0.3412\n",
      "Model saved at the end of epoch 16.\n",
      "Epoch: 17. Tra Loss: 0.3672. Val Loss: 0.4166. Syn Loss: 0.3553\n",
      "Model saved at the end of epoch 17.\n",
      "Epoch: 18. Tra Loss: 0.3646. Val Loss: 0.3821. Syn Loss: 0.3308\n",
      "Model saved at the end of epoch 18.\n",
      "Epoch: 19. Tra Loss: 0.3626. Val Loss: 0.5503. Syn Loss: 0.4862\n",
      "Model saved at the end of epoch 19.\n",
      "Epoch: 20. Tra Loss: 0.3636. Val Loss: 0.3686. Syn Loss: 0.3057\n",
      "Model saved at the end of epoch 20.\n",
      "Epoch: 21. Tra Loss: 0.3602. Val Loss: 0.3971. Syn Loss: 0.3369\n",
      "Model saved at the end of epoch 21.\n",
      "Epoch: 22. Tra Loss: 0.3598. Val Loss: 0.3801. Syn Loss: 0.3237\n",
      "Model saved at the end of epoch 22.\n",
      "Epoch: 23. Tra Loss: 0.3577. Val Loss: 0.3682. Syn Loss: 0.3080\n",
      "Model saved at the end of epoch 23.\n",
      "Epoch: 24. Tra Loss: 0.3561. Val Loss: 0.3609. Syn Loss: 0.2908\n",
      "Model saved at the end of epoch 24.\n",
      "Epoch: 25. Tra Loss: 0.3556. Val Loss: 0.6713. Syn Loss: 0.6221\n",
      "Model saved at the end of epoch 25.\n",
      "Epoch: 26. Tra Loss: 0.3533. Val Loss: 0.3648. Syn Loss: 0.3114\n",
      "Model saved at the end of epoch 26.\n",
      "Epoch: 27. Tra Loss: 0.3513. Val Loss: 0.3591. Syn Loss: 0.2954\n",
      "Model saved at the end of epoch 27.\n",
      "Epoch: 28. Tra Loss: 0.3478. Val Loss: 0.3591. Syn Loss: 0.3037\n",
      "Model saved at the end of epoch 28.\n",
      "Epoch: 29. Tra Loss: 0.3460. Val Loss: 0.3597. Syn Loss: 0.2993\n",
      "Model saved at the end of epoch 29.\n",
      "Epoch: 30. Tra Loss: 0.3447. Val Loss: 0.3643. Syn Loss: 0.3050\n",
      "Model saved at the end of epoch 30.\n",
      "Epoch: 31. Tra Loss: 0.3436. Val Loss: 0.3551. Syn Loss: 0.2910\n",
      "Model saved at the end of epoch 31.\n",
      "Epoch: 32. Tra Loss: 0.3426. Val Loss: 0.3513. Syn Loss: 0.2809\n",
      "Model saved at the end of epoch 32.\n",
      "Epoch: 33. Tra Loss: 0.3418. Val Loss: 0.3489. Syn Loss: 0.2779\n",
      "Model saved at the end of epoch 33.\n",
      "Epoch: 34. Tra Loss: 0.3410. Val Loss: 0.3483. Syn Loss: 0.2803\n",
      "Model saved at the end of epoch 34.\n",
      "Epoch: 35. Tra Loss: 0.3403. Val Loss: 0.3489. Syn Loss: 0.2799\n",
      "Model saved at the end of epoch 35.\n",
      "Epoch: 36. Tra Loss: 0.3397. Val Loss: 0.3497. Syn Loss: 0.2785\n",
      "Model saved at the end of epoch 36.\n",
      "Epoch: 37. Tra Loss: 0.3391. Val Loss: 0.3498. Syn Loss: 0.2837\n",
      "Model saved at the end of epoch 37.\n",
      "Epoch: 38. Tra Loss: 0.3384. Val Loss: 0.3475. Syn Loss: 0.2809\n",
      "Model saved at the end of epoch 38.\n",
      "Epoch: 39. Tra Loss: 0.3378. Val Loss: 0.3495. Syn Loss: 0.2866\n",
      "Model saved at the end of epoch 39.\n",
      "Epoch: 40. Tra Loss: 0.3373. Val Loss: 0.3488. Syn Loss: 0.2855\n",
      "Model saved at the end of epoch 40.\n",
      "Epoch: 41. Tra Loss: 0.3368. Val Loss: 0.3495. Syn Loss: 0.2834\n",
      "Model saved at the end of epoch 41.\n",
      "Epoch: 42. Tra Loss: 0.3363. Val Loss: 0.3482. Syn Loss: 0.2821\n",
      "Model saved at the end of epoch 42.\n",
      "Epoch: 43. Tra Loss: 0.3358. Val Loss: 0.3528. Syn Loss: 0.2895\n",
      "Model saved at the end of epoch 43.\n",
      "Epoch: 44. Tra Loss: 0.3352. Val Loss: 0.3487. Syn Loss: 0.2840\n",
      "Model saved at the end of epoch 44.\n",
      "Epoch: 45. Tra Loss: 0.3348. Val Loss: 0.3508. Syn Loss: 0.2877\n",
      "Model saved at the end of epoch 45.\n",
      "Epoch: 46. Tra Loss: 0.3343. Val Loss: 0.3514. Syn Loss: 0.2873\n",
      "Model saved at the end of epoch 46.\n",
      "Epoch: 47. Tra Loss: 0.3340. Val Loss: 0.3455. Syn Loss: 0.2803\n",
      "Model saved at the end of epoch 47.\n",
      "Epoch: 48. Tra Loss: 0.3335. Val Loss: 0.3471. Syn Loss: 0.2795\n",
      "Model saved at the end of epoch 48.\n",
      "Epoch: 49. Tra Loss: 0.3332. Val Loss: 0.3473. Syn Loss: 0.2846\n",
      "Model saved at the end of epoch 49.\n",
      "Epoch: 50. Tra Loss: 0.3327. Val Loss: 0.3502. Syn Loss: 0.2869\n",
      "Model saved at the end of epoch 50.\n",
      "Epoch: 51. Tra Loss: 0.3323. Val Loss: 0.3470. Syn Loss: 0.2820\n",
      "Model saved at the end of epoch 51.\n",
      "Epoch: 52. Tra Loss: 0.3320. Val Loss: 0.3492. Syn Loss: 0.2822\n",
      "Model saved at the end of epoch 52.\n",
      "Epoch: 53. Tra Loss: 0.3315. Val Loss: 0.3488. Syn Loss: 0.2828\n",
      "Model saved at the end of epoch 53.\n",
      "Epoch: 54. Tra Loss: 0.3309. Val Loss: 0.3493. Syn Loss: 0.2836\n",
      "Model saved at the end of epoch 54.\n",
      "Epoch: 55. Tra Loss: 0.3308. Val Loss: 0.3505. Syn Loss: 0.2862\n",
      "Model saved at the end of epoch 55.\n",
      "Epoch: 56. Tra Loss: 0.3304. Val Loss: 0.3502. Syn Loss: 0.2857\n",
      "Model saved at the end of epoch 56.\n",
      "Epoch: 57. Tra Loss: 0.3300. Val Loss: 0.3485. Syn Loss: 0.2805\n",
      "Model saved at the end of epoch 57.\n",
      "Epoch: 58. Tra Loss: 0.3298. Val Loss: 0.3489. Syn Loss: 0.2799\n",
      "Model saved at the end of epoch 58.\n",
      "Epoch: 59. Tra Loss: 0.3293. Val Loss: 0.3506. Syn Loss: 0.2948\n",
      "Model saved at the end of epoch 59.\n",
      "Epoch: 60. Tra Loss: 0.3289. Val Loss: 0.3467. Syn Loss: 0.2845\n",
      "Model saved at the end of epoch 60.\n",
      "Epoch: 61. Tra Loss: 0.3287. Val Loss: 0.3475. Syn Loss: 0.2816\n",
      "Model saved at the end of epoch 61.\n",
      "Epoch: 62. Tra Loss: 0.3283. Val Loss: 0.3499. Syn Loss: 0.2850\n",
      "Model saved at the end of epoch 62.\n",
      "Epoch: 63. Tra Loss: 0.3281. Val Loss: 0.3480. Syn Loss: 0.2835\n",
      "Model saved at the end of epoch 63.\n",
      "Epoch: 64. Tra Loss: 0.3276. Val Loss: 0.3469. Syn Loss: 0.2773\n",
      "Model saved at the end of epoch 64.\n",
      "Epoch: 65. Tra Loss: 0.3271. Val Loss: 0.3471. Syn Loss: 0.2809\n",
      "Model saved at the end of epoch 65.\n",
      "Epoch: 66. Tra Loss: 0.3269. Val Loss: 0.3466. Syn Loss: 0.2808\n",
      "Model saved at the end of epoch 66.\n",
      "Epoch: 67. Tra Loss: 0.3266. Val Loss: 0.3485. Syn Loss: 0.2798\n",
      "Model saved at the end of epoch 67.\n",
      "Epoch: 68. Tra Loss: 0.3261. Val Loss: 0.3496. Syn Loss: 0.2811\n",
      "Model saved at the end of epoch 68.\n",
      "Epoch: 69. Tra Loss: 0.3259. Val Loss: 0.3485. Syn Loss: 0.2801\n",
      "Model saved at the end of epoch 69.\n",
      "Epoch: 70. Tra Loss: 0.3256. Val Loss: 0.3487. Syn Loss: 0.2785\n",
      "Model saved at the end of epoch 70.\n",
      "Epoch: 71. Tra Loss: 0.3253. Val Loss: 0.3488. Syn Loss: 0.2782\n",
      "Model saved at the end of epoch 71.\n",
      "Epoch: 72. Tra Loss: 0.3249. Val Loss: 0.3495. Syn Loss: 0.2863\n",
      "Model saved at the end of epoch 72.\n",
      "Epoch: 73. Tra Loss: 0.3247. Val Loss: 0.3493. Syn Loss: 0.2784\n",
      "Model saved at the end of epoch 73.\n",
      "Epoch: 74. Tra Loss: 0.3243. Val Loss: 0.3494. Syn Loss: 0.2781\n",
      "Model saved at the end of epoch 74.\n",
      "Epoch: 75. Tra Loss: 0.3240. Val Loss: 0.3484. Syn Loss: 0.2785\n",
      "Model saved at the end of epoch 75.\n",
      "Epoch: 76. Tra Loss: 0.3237. Val Loss: 0.3488. Syn Loss: 0.2844\n",
      "Model saved at the end of epoch 76.\n",
      "Epoch: 77. Tra Loss: 0.3235. Val Loss: 0.3475. Syn Loss: 0.2775\n",
      "Model saved at the end of epoch 77.\n",
      "Epoch: 78. Tra Loss: 0.3234. Val Loss: 0.3500. Syn Loss: 0.2822\n",
      "Model saved at the end of epoch 78.\n",
      "Epoch: 79. Tra Loss: 0.3228. Val Loss: 0.3487. Syn Loss: 0.2777\n",
      "Model saved at the end of epoch 79.\n",
      "Epoch: 80. Tra Loss: 0.3228. Val Loss: 0.3493. Syn Loss: 0.2811\n",
      "Model saved at the end of epoch 80.\n",
      "Epoch: 81. Tra Loss: 0.3225. Val Loss: 0.3495. Syn Loss: 0.2759\n",
      "Model saved at the end of epoch 81.\n",
      "Epoch: 82. Tra Loss: 0.3223. Val Loss: 0.3512. Syn Loss: 0.2822\n",
      "Model saved at the end of epoch 82.\n",
      "Epoch: 83. Tra Loss: 0.3219. Val Loss: 0.3505. Syn Loss: 0.2746\n",
      "Model saved at the end of epoch 83.\n",
      "Epoch: 84. Tra Loss: 0.3217. Val Loss: 0.3504. Syn Loss: 0.2763\n",
      "Model saved at the end of epoch 84.\n",
      "Epoch: 85. Tra Loss: 0.3214. Val Loss: 0.3518. Syn Loss: 0.2839\n",
      "Model saved at the end of epoch 85.\n",
      "Epoch: 86. Tra Loss: 0.3212. Val Loss: 0.3532. Syn Loss: 0.2863\n",
      "Model saved at the end of epoch 86.\n",
      "Epoch: 87. Tra Loss: 0.3209. Val Loss: 0.3547. Syn Loss: 0.2841\n",
      "Model saved at the end of epoch 87.\n",
      "Epoch: 88. Tra Loss: 0.3204. Val Loss: 0.3510. Syn Loss: 0.2809\n",
      "Model saved at the end of epoch 88.\n",
      "Epoch: 89. Tra Loss: 0.3205. Val Loss: 0.3501. Syn Loss: 0.2802\n",
      "Model saved at the end of epoch 89.\n",
      "Epoch: 90. Tra Loss: 0.3198. Val Loss: 0.3514. Syn Loss: 0.2762\n",
      "Model saved at the end of epoch 90.\n",
      "Epoch: 91. Tra Loss: 0.3197. Val Loss: 0.3496. Syn Loss: 0.2760\n",
      "Model saved at the end of epoch 91.\n",
      "Epoch: 92. Tra Loss: 0.3197. Val Loss: 0.3529. Syn Loss: 0.2799\n",
      "Model saved at the end of epoch 92.\n",
      "Epoch: 93. Tra Loss: 0.3193. Val Loss: 0.3526. Syn Loss: 0.2803\n",
      "Model saved at the end of epoch 93.\n",
      "Epoch: 94. Tra Loss: 0.3190. Val Loss: 0.3515. Syn Loss: 0.2788\n",
      "Model saved at the end of epoch 94.\n",
      "Epoch: 95. Tra Loss: 0.3189. Val Loss: 0.3518. Syn Loss: 0.2788\n",
      "Model saved at the end of epoch 95.\n",
      "Epoch: 96. Tra Loss: 0.3186. Val Loss: 0.3517. Syn Loss: 0.2809\n",
      "Model saved at the end of epoch 96.\n",
      "Epoch: 97. Tra Loss: 0.3183. Val Loss: 0.3519. Syn Loss: 0.2808\n",
      "Model saved at the end of epoch 97.\n",
      "Epoch: 98. Tra Loss: 0.3182. Val Loss: 0.3527. Syn Loss: 0.2806\n",
      "Model saved at the end of epoch 98.\n",
      "Epoch: 99. Tra Loss: 0.3180. Val Loss: 0.3529. Syn Loss: 0.2808\n",
      "Model saved at the end of epoch 99.\n",
      "Epoch: 100. Tra Loss: 0.3177. Val Loss: 0.3538. Syn Loss: 0.2806\n",
      "Model saved at the end of epoch 100.\n",
      "Epoch: 101. Tra Loss: 0.3176. Val Loss: 0.3541. Syn Loss: 0.2791\n",
      "Model saved at the end of epoch 101.\n",
      "Epoch: 102. Tra Loss: 0.3173. Val Loss: 0.3534. Syn Loss: 0.2812\n",
      "Model saved at the end of epoch 102.\n",
      "Epoch: 103. Tra Loss: 0.3170. Val Loss: 0.3536. Syn Loss: 0.2777\n",
      "Model saved at the end of epoch 103.\n",
      "Epoch: 104. Tra Loss: 0.3167. Val Loss: 0.3528. Syn Loss: 0.2770\n",
      "Model saved at the end of epoch 104.\n",
      "Epoch: 105. Tra Loss: 0.3166. Val Loss: 0.3523. Syn Loss: 0.2788\n",
      "Model saved at the end of epoch 105.\n",
      "Epoch: 106. Tra Loss: 0.3162. Val Loss: 0.3542. Syn Loss: 0.2757\n",
      "Model saved at the end of epoch 106.\n",
      "Epoch: 107. Tra Loss: 0.3161. Val Loss: 0.3540. Syn Loss: 0.2772\n",
      "Model saved at the end of epoch 107.\n",
      "Epoch: 108. Tra Loss: 0.3159. Val Loss: 0.3530. Syn Loss: 0.2778\n",
      "Model saved at the end of epoch 108.\n",
      "Epoch: 109. Tra Loss: 0.3156. Val Loss: 0.3548. Syn Loss: 0.2767\n",
      "Model saved at the end of epoch 109.\n",
      "Epoch: 110. Tra Loss: 0.3156. Val Loss: 0.3520. Syn Loss: 0.2757\n",
      "Model saved at the end of epoch 110.\n",
      "Epoch: 111. Tra Loss: 0.3151. Val Loss: 0.3547. Syn Loss: 0.2765\n",
      "Model saved at the end of epoch 111.\n",
      "Epoch: 112. Tra Loss: 0.3150. Val Loss: 0.3550. Syn Loss: 0.2782\n",
      "Model saved at the end of epoch 112.\n",
      "Epoch: 113. Tra Loss: 0.3148. Val Loss: 0.3539. Syn Loss: 0.2779\n",
      "Model saved at the end of epoch 113.\n",
      "Epoch: 114. Tra Loss: 0.3146. Val Loss: 0.3535. Syn Loss: 0.2771\n",
      "Model saved at the end of epoch 114.\n",
      "Epoch: 115. Tra Loss: 0.3146. Val Loss: 0.3541. Syn Loss: 0.2762\n",
      "Model saved at the end of epoch 115.\n",
      "Epoch: 116. Tra Loss: 0.3143. Val Loss: 0.3538. Syn Loss: 0.2769\n",
      "Model saved at the end of epoch 116.\n",
      "Epoch: 117. Tra Loss: 0.3139. Val Loss: 0.3549. Syn Loss: 0.2763\n",
      "Model saved at the end of epoch 117.\n",
      "Epoch: 118. Tra Loss: 0.3138. Val Loss: 0.3552. Syn Loss: 0.2806\n",
      "Model saved at the end of epoch 118.\n",
      "Epoch: 119. Tra Loss: 0.3136. Val Loss: 0.3552. Syn Loss: 0.2811\n",
      "Model saved at the end of epoch 119.\n",
      "Epoch: 120. Tra Loss: 0.3135. Val Loss: 0.3544. Syn Loss: 0.2813\n",
      "Model saved at the end of epoch 120.\n",
      "Epoch: 121. Tra Loss: 0.3133. Val Loss: 0.3536. Syn Loss: 0.2789\n",
      "Model saved at the end of epoch 121.\n",
      "Epoch: 122. Tra Loss: 0.3133. Val Loss: 0.3538. Syn Loss: 0.2748\n",
      "Model saved at the end of epoch 122.\n",
      "Epoch: 123. Tra Loss: 0.3128. Val Loss: 0.3542. Syn Loss: 0.2775\n",
      "Model saved at the end of epoch 123.\n",
      "Epoch: 124. Tra Loss: 0.3129. Val Loss: 0.3533. Syn Loss: 0.2709\n",
      "Model saved at the end of epoch 124.\n",
      "Epoch: 125. Tra Loss: 0.3125. Val Loss: 0.3542. Syn Loss: 0.2776\n",
      "Model saved at the end of epoch 125.\n",
      "Epoch: 126. Tra Loss: 0.3124. Val Loss: 0.3538. Syn Loss: 0.2762\n",
      "Model saved at the end of epoch 126.\n",
      "Epoch: 127. Tra Loss: 0.3123. Val Loss: 0.3569. Syn Loss: 0.2793\n",
      "Model saved at the end of epoch 127.\n",
      "Epoch: 128. Tra Loss: 0.3120. Val Loss: 0.3552. Syn Loss: 0.2750\n",
      "Model saved at the end of epoch 128.\n",
      "Epoch: 129. Tra Loss: 0.3118. Val Loss: 0.3553. Syn Loss: 0.2759\n",
      "Model saved at the end of epoch 129.\n",
      "Epoch: 130. Tra Loss: 0.3116. Val Loss: 0.3552. Syn Loss: 0.2750\n",
      "Model saved at the end of epoch 130.\n",
      "Epoch: 131. Tra Loss: 0.3114. Val Loss: 0.3550. Syn Loss: 0.2711\n",
      "Model saved at the end of epoch 131.\n",
      "Epoch: 132. Tra Loss: 0.3114. Val Loss: 0.3544. Syn Loss: 0.2751\n",
      "Model saved at the end of epoch 132.\n",
      "Epoch: 133. Tra Loss: 0.3110. Val Loss: 0.3579. Syn Loss: 0.2761\n",
      "Model saved at the end of epoch 133.\n",
      "Epoch: 134. Tra Loss: 0.3110. Val Loss: 0.3553. Syn Loss: 0.2755\n",
      "Model saved at the end of epoch 134.\n",
      "Epoch: 135. Tra Loss: 0.3104. Val Loss: 0.3548. Syn Loss: 0.2696\n",
      "Model saved at the end of epoch 135.\n",
      "Epoch: 136. Tra Loss: 0.3108. Val Loss: 0.3574. Syn Loss: 0.2706\n",
      "Model saved at the end of epoch 136.\n",
      "Epoch: 137. Tra Loss: 0.3103. Val Loss: 0.3565. Syn Loss: 0.2690\n",
      "Model saved at the end of epoch 137.\n",
      "Epoch: 138. Tra Loss: 0.3101. Val Loss: 0.3564. Syn Loss: 0.2722\n",
      "Model saved at the end of epoch 138.\n",
      "Epoch: 139. Tra Loss: 0.3099. Val Loss: 0.3553. Syn Loss: 0.2730\n",
      "Model saved at the end of epoch 139.\n",
      "Epoch: 140. Tra Loss: 0.3097. Val Loss: 0.3573. Syn Loss: 0.2738\n",
      "Model saved at the end of epoch 140.\n",
      "Epoch: 141. Tra Loss: 0.3096. Val Loss: 0.3565. Syn Loss: 0.2752\n",
      "Model saved at the end of epoch 141.\n",
      "Epoch: 142. Tra Loss: 0.3095. Val Loss: 0.3551. Syn Loss: 0.2751\n",
      "Model saved at the end of epoch 142.\n",
      "Epoch: 143. Tra Loss: 0.3093. Val Loss: 0.3563. Syn Loss: 0.2751\n",
      "Model saved at the end of epoch 143.\n",
      "Epoch: 144. Tra Loss: 0.3090. Val Loss: 0.3553. Syn Loss: 0.2767\n",
      "Model saved at the end of epoch 144.\n",
      "Epoch: 145. Tra Loss: 0.3090. Val Loss: 0.3551. Syn Loss: 0.2732\n",
      "Model saved at the end of epoch 145.\n",
      "Epoch: 146. Tra Loss: 0.3088. Val Loss: 0.3560. Syn Loss: 0.2742\n",
      "Model saved at the end of epoch 146.\n",
      "Epoch: 147. Tra Loss: 0.3086. Val Loss: 0.3564. Syn Loss: 0.2743\n",
      "Model saved at the end of epoch 147.\n",
      "Epoch: 148. Tra Loss: 0.3086. Val Loss: 0.3565. Syn Loss: 0.2755\n",
      "Model saved at the end of epoch 148.\n",
      "Epoch: 149. Tra Loss: 0.3082. Val Loss: 0.3580. Syn Loss: 0.2773\n",
      "Model saved at the end of epoch 149.\n",
      "Epoch: 150. Tra Loss: 0.3082. Val Loss: 0.3562. Syn Loss: 0.2762\n",
      "Model saved at the end of epoch 150.\n",
      "Epoch: 151. Tra Loss: 0.3079. Val Loss: 0.3559. Syn Loss: 0.2759\n",
      "Training completed in 9515.66 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "mean_tra_losses = []\n",
    "mean_val_losses = []\n",
    "mean_syn_losses = []\n",
    "val_data = []\n",
    "syn_data = []\n",
    "\n",
    "start = time.time()\n",
    "epoch = 0\n",
    "while epoch <= epochs:\n",
    "    tra_losses = []\n",
    "    val_losses = []\n",
    "    syn_losses = []\n",
    "    model.train()\n",
    "    \n",
    "    # Training loop\n",
    "    for images, masks in tra_loader:\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = my_loss(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tra_losses.append(loss.data)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    for images, masks in val_loader:\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            val_loss = my_loss(outputs, masks)\n",
    "            val_losses.append(val_loss.data)\n",
    "            if (epoch > patience and abs(mean_val_losses[-patience] - mean_val_losses[-1]) < threshold) or epoch == epochs:\n",
    "                val_data.extend([[outputs, masks, images]])\n",
    "\n",
    "    # Synthesis loop\n",
    "    for images, masks in syn_loader:\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            syn_loss = my_loss(outputs, masks)\n",
    "            syn_losses.append(syn_loss.data)\n",
    "            if (epoch > patience and abs(mean_val_losses[-patience] - mean_val_losses[-1]) < threshold) or epoch == epochs:\n",
    "                syn_data.extend([[outputs, masks, images]])\n",
    "\n",
    "   \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'epoch_model_vignn_noise.pth')  # Save at the end of every epoch\n",
    "    print(f\"Model saved at the end of epoch {epoch}.\")\n",
    "    \n",
    "    # Update losses and print progress\n",
    "    epoch += 1\n",
    "    mean_tra_losses.append(torch.mean(torch.stack(tra_losses)))\n",
    "    mean_val_losses.append(torch.mean(torch.stack(val_losses)))\n",
    "    mean_syn_losses.append(torch.mean(torch.stack(syn_losses)))\n",
    "    print(f'Epoch: {epoch}. Tra Loss: {torch.mean(torch.stack(tra_losses)):.4f}. Val Loss: {torch.mean(torch.stack(val_losses)):.4f}. Syn Loss: {torch.mean(torch.stack(syn_losses)):.4f}')\n",
    "\n",
    "end = time.time()\n",
    "run_time = end - start\n",
    "print(f\"Training completed in {run_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_File = 'epoch_model_vignn_noise.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Loads trained weights and evaluates performance on irregular(Val)/irregular(Syn) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for evaluation\n",
    "val_data = []\n",
    "syn_data = []\n",
    "model.load_state_dict(torch.load(model_File),strict=False)\n",
    "model.eval()\n",
    "for images, masks in val_loader:\n",
    "    with torch.no_grad():\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        outputs = model(images)\n",
    "        val_data.extend([[outputs, masks, images]])\n",
    "\n",
    "for images, masks in syn_loader:\n",
    "    with torch.no_grad():\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        outputs = model(images)\n",
    "        syn_data.extend([[outputs, masks, images]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data = np.array(val_data)\n",
    "val_truth = []\n",
    "val_predict = []\n",
    "val_truth_d = []\n",
    "for p, q in enumerate(val_data):\n",
    "    for i, j in enumerate(q[1]):\n",
    "        val_truth.append(j.reshape(1, 16384)[0].cpu().numpy())\n",
    "    for i, j in enumerate(q[0]):\n",
    "        val_predict.append(j.reshape(1, 16384)[0].cpu().numpy())\n",
    "    for i, j in enumerate(q[2]):\n",
    "        val_truth_d.append(j.reshape(1, 1024)[0].cpu().numpy())\n",
    "\n",
    "# syn_data = np.array(syn_data)\n",
    "syn_truth = []\n",
    "syn_predict = []\n",
    "syn_truth_d = []\n",
    "for p, q in enumerate(syn_data):\n",
    "    for i, j in enumerate(q[1]):\n",
    "        syn_truth.append(j.reshape(1, 16384)[0].cpu().numpy())\n",
    "    for i, j in enumerate(q[0]):\n",
    "        syn_predict.append(j.reshape(1, 16384)[0].cpu().numpy())\n",
    "    for i, j in enumerate(q[2]):\n",
    "        syn_truth_d.append(j.reshape(1, 1024)[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384,)\n",
      "(16384,)\n",
      "(1024,)\n",
      "(16384,)\n",
      "(16384,)\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "print(val_truth[0].shape)\n",
    "print(val_predict[0].shape)\n",
    "print(val_truth_d[0].shape)\n",
    "\n",
    "print(syn_truth[0].shape)\n",
    "print(syn_predict[0].shape)\n",
    "print(syn_truth_d[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E  : Reconstruction error (relative L2 norm error)\n",
    "### R2 : Coefficient of determination between true and inverted gravity anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rel = []\n",
    "val_R_2 = []\n",
    "syn_rel = []\n",
    "syn_R_2 = []\n",
    "for i in range(len(val_x)):\n",
    "    val_rel.append(np.linalg.norm(np.array(val_predict[i]) - np.array(val_truth[i]), 2)/np.linalg.norm(np.array(val_truth[i]), 2))\n",
    "    tru_d = val_truth_d[i].reshape(1024, 1)\n",
    "    pre_d = np.asmatrix(G)*np.asmatrix(density*val_predict[i].reshape(16384, 1))\n",
    "    val_R_2.append(1- np.sum(np.power(tru_d - pre_d, 2))/np.sum(np.power(tru_d - np.mean(tru_d), 2)))\n",
    "\n",
    "E = [np.array(val_rel).mean()]\n",
    "R_2 = [np.array(val_R_2).mean()]\n",
    "\n",
    "for i in range(len(syn_x)):\n",
    "    syn_rel.append(np.linalg.norm(np.array(syn_predict[i]) - np.array(syn_truth[i]), 2)/np.linalg.norm(np.array(syn_truth[i]), 2))\n",
    "    tru_d = syn_truth_d[i].reshape(1024, 1)\n",
    "    pre_d = np.asmatrix(G)*np.asmatrix(density*syn_predict[i].reshape(16384, 1))\n",
    "    syn_R_2.append(1 - np.sum(np.power(tru_d - pre_d, 2))/np.sum(np.power(tru_d - np.mean(tru_d), 2)))\n",
    "\n",
    "for i in range(category):\n",
    "    E.append(np.array(syn_rel)[part_num*i: part_num*(i+1)].mean())\n",
    "    R_2.append(np.array(syn_R_2)[part_num*i: part_num*(i+1)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8082153, 0.62046206, 0.6970419, 0.78861696, 0.7407719, 0.6827521, 0.7646583]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
