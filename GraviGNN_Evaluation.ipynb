{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraviGNN: Gravity Inversion using Graph Neural Networks\n",
    "\n",
    "This notebook provides evaluation code for the **GraviGNN** model used for gravity anomaly inversion.\n",
    "\n",
    "### Contents\n",
    "- Import Libraries\n",
    "- Hyperparameter Setup\n",
    "- Model Architecture\n",
    "- Loss Functions\n",
    "- Dataset Loading\n",
    "- Model Training\n",
    "- Evaluation on Synthetic Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "This section imports all required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as colors\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "plt.rc('font',family='Times New Roman', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training Hyperparameters\n",
    "\n",
    "Defines core training parameters including:\n",
    "- Number of epochs\n",
    "- Learning rate\n",
    "- Early stopping patience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 20\n",
    "epochs = 180\n",
    "tra_num = 20000\n",
    "val_num = 2000\n",
    "part_num = 100\n",
    "category = 6\n",
    "batch_size = 16\n",
    "num_cell = 32\n",
    "learning_rate = 4e-4\n",
    "threshold = 1e-4\n",
    "realdata_num = 1\n",
    "start_fm = 32\n",
    "syn_num = part_num*category\n",
    "total_num = tra_num + val_num\n",
    "\n",
    "\n",
    "# Physical parameters\n",
    "density = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture\n",
    "\n",
    "Defines the neural network components used in GraviGNN.\n",
    "This includes:\n",
    "- Double convolution blocks\n",
    "- Encoder-decoder structure\n",
    "- Final prediction layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Standard double convolution block (used for local feature extraction)\n",
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.ELU = nn.ELU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ELU(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "##############################################\n",
    "# Graph Convolution with Multi-Head Updates\n",
    "##############################################\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph convolution that:\n",
    "      1. Computes K-nearest neighbors based on Euclidean distance.\n",
    "      2. Aggregates neighbor features via an elementwise maximum.\n",
    "      3. Concatenates the original node feature with the aggregated neighbor feature.\n",
    "      4. Applies multi-head linear updates.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, k=8):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.k = k\n",
    "        assert out_dim % num_heads == 0, \"out_dim must be divisible by num_heads\"\n",
    "        self.head_dim = out_dim // num_heads\n",
    "        # Create a separate linear layer for each head.\n",
    "        self.linears = nn.ModuleList([nn.Linear(2 * in_dim, self.head_dim) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, N, D)\n",
    "        B, N, D = x.shape\n",
    "\n",
    "        # Compute pairwise Euclidean distances: shape (B, N, N)\n",
    "        dist = torch.cdist(x, x, p=2)\n",
    "        # Mask self-distance by setting diagonal entries to infinity\n",
    "        diag = torch.eye(N, device=x.device).bool().unsqueeze(0)\n",
    "        dist.masked_fill_(diag, float('inf'))\n",
    "        # Select effective k to avoid selecting more neighbors than available\n",
    "        effective_k = self.k if self.k < N else N - 1\n",
    "        # Get indices of k nearest neighbors (smallest distances)\n",
    "        knn_indices = torch.topk(-dist, k=effective_k, dim=-1).indices  # shape: (B, N, effective_k)\n",
    "\n",
    "        # Gather neighbor features using advanced indexing\n",
    "        batch_indices = torch.arange(B, device=x.device).view(B, 1, 1).expand(B, N, effective_k)\n",
    "        neighbors = x[batch_indices, knn_indices]  # shape: (B, N, effective_k, D)\n",
    "\n",
    "        # Aggregate neighbors with elementwise maximum across the k dimension\n",
    "        agg, _ = torch.max(neighbors, dim=2)  # shape: (B, N, D)\n",
    "\n",
    "        # Concatenate the original feature with the aggregated neighbor feature\n",
    "        concat_feat = torch.cat([x, agg], dim=-1)  # (B, N, 2*D)\n",
    "\n",
    "        # Multi-head update: apply a separate linear projection per head and concatenate\n",
    "        head_outputs = []\n",
    "        for linear in self.linears:\n",
    "            head_outputs.append(linear(concat_feat))  # each: (B, N, head_dim)\n",
    "        out = torch.cat(head_outputs, dim=-1)  # (B, N, out_dim)\n",
    "        return out\n",
    "\n",
    "##############################################\n",
    "# ViG Block: Graph-level processing with enhancement\n",
    "##############################################\n",
    "\n",
    "class ViGBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ViG block that applies:\n",
    "      - A graph convolution (with pre- and post- linear projections and nonlinear activations)\n",
    "      - A feed-forward network (FFN) to further refine node features.\n",
    "      \n",
    "    The block follows:\n",
    "         Y = (GraphConv(X * W_in)) * W_out + X\n",
    "         Z = FFN(Y) + Y\n",
    "    with normalization (LayerNorm) and dropout to help prevent over-smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, k=8, ff_hidden_dim=None, dropout=0.1):\n",
    "        super(ViGBlock, self).__init__()\n",
    "        ff_hidden_dim = ff_hidden_dim or in_dim * 2\n",
    "        self.proj_in = nn.Linear(in_dim, in_dim)\n",
    "        self.graph_conv = GraphConv(in_dim, out_dim, num_heads=num_heads, k=k)\n",
    "        self.proj_out = nn.Linear(out_dim, out_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(out_dim)\n",
    "        # Feed-forward network (FFN)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(out_dim, ff_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_dim, out_dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, N, D)\n",
    "        x_proj = self.proj_in(x)  # project into same domain: (B, N, D)\n",
    "        gc = self.graph_conv(x_proj)  # graph convolution: (B, N, out_dim)\n",
    "        gc = self.proj_out(gc)\n",
    "        gc = self.activation(gc)\n",
    "        gc = self.dropout(gc)\n",
    "        y = x + gc  # residual connection\n",
    "        y = self.norm1(y)\n",
    "        # FFN to further refine features\n",
    "        ffn_out = self.ffn(y)\n",
    "        ffn_out = self.dropout(ffn_out)\n",
    "        out = y + ffn_out  # residual connection\n",
    "        out = self.norm2(out)\n",
    "        return out\n",
    "\n",
    "##############################################\n",
    "# ViG-based UNet Architecture (Pyramid Architecture)\n",
    "##############################################\n",
    "\n",
    "class ViGUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    This network combines CNN-based patch processing with graph neural network modules.\n",
    "    \n",
    "    Unified Flow Summary:\n",
    "       1. Input Processing:\n",
    "          - An image is divided into patches.\n",
    "          - Each patch is converted into a feature vector to form matrix X.\n",
    "       2. Graph Construction:\n",
    "          - A graph G is built where each node represents a patch.\n",
    "          - Edges are created by connecting each node to its K nearest neighbors.\n",
    "       3. Graph Convolution and Multi-Head Updates:\n",
    "          - Graph convolution aggregates neighbor information via a max-relative function.\n",
    "          - Features are updated via a multi-head mechanism.\n",
    "       4. ViG Block Enhancement:\n",
    "          - A Grapher module (ViGBlock) uses pre- and post- projections, nonlinear activations, and residual connections.\n",
    "          - An FFN further refines node features.\n",
    "       5. Network Architectures:\n",
    "          - The ViG blocks are stacked to form a UNet-like encoder-decoder (pyramid) architecture.\n",
    "    \n",
    "    This complete flow leverages graph neural network principles with modern network design strategies.\n",
    "    \"\"\"\n",
    "    def __init__(self, start_fm=32, num_heads=4, ff_hidden_dim=None, dropout=0.1, k=8):\n",
    "        super(ViGUNet, self).__init__()\n",
    "        self.start_fm = start_fm\n",
    "\n",
    "        # Encoder Stage 1\n",
    "        self.enc1_conv = double_conv(1, start_fm)\n",
    "        self.enc1_vig = ViGBlock(start_fm, start_fm, num_heads=num_heads, k=k, dropout=dropout)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Encoder Stage 2\n",
    "        self.enc2_conv = double_conv(start_fm, start_fm * 2)\n",
    "        self.enc2_vig = ViGBlock(start_fm * 2, start_fm * 2, num_heads=num_heads, k=k, dropout=dropout)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Encoder Stage 3\n",
    "        self.enc3_conv = double_conv(start_fm * 2, start_fm * 4)\n",
    "        self.enc3_vig = ViGBlock(start_fm * 4, start_fm * 4, num_heads=num_heads, k=k, dropout=dropout)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Encoder Stage 4\n",
    "        self.enc4_conv = double_conv(start_fm * 4, start_fm * 8)\n",
    "        self.enc4_vig = ViGBlock(start_fm * 8, start_fm * 8, num_heads=num_heads, k=k, dropout=dropout)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck_conv = double_conv(start_fm * 8, start_fm * 16)\n",
    "        self.bottleneck_vig = ViGBlock(start_fm * 16, start_fm * 16, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        # Decoder Stage 4\n",
    "        self.up4 = nn.ConvTranspose2d(start_fm * 16, start_fm * 8, kernel_size=2, stride=2)\n",
    "        self.dec4_conv = double_conv(start_fm * 16, start_fm * 8)\n",
    "        self.dec4_vig = ViGBlock(start_fm * 8, start_fm * 8, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        # Decoder Stage 3\n",
    "        self.up3 = nn.ConvTranspose2d(start_fm * 8, start_fm * 4, kernel_size=2, stride=2)\n",
    "        self.dec3_conv = double_conv(start_fm * 8, start_fm * 4)\n",
    "        self.dec3_vig = ViGBlock(start_fm * 4, start_fm * 4, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        # Decoder Stage 2\n",
    "        self.up2 = nn.ConvTranspose2d(start_fm * 4, start_fm * 2, kernel_size=2, stride=2)\n",
    "        self.dec2_conv = double_conv(start_fm * 4, start_fm * 2)\n",
    "        self.dec2_vig = ViGBlock(start_fm * 2, start_fm * 2, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        # Decoder Stage 1\n",
    "        self.up1 = nn.ConvTranspose2d(start_fm * 2, start_fm, kernel_size=2, stride=2)\n",
    "        self.dec1_conv = double_conv(start_fm * 2, start_fm)\n",
    "        self.dec1_vig = ViGBlock(start_fm, start_fm, num_heads=num_heads, k=k, dropout=dropout)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(start_fm, 16, kernel_size=1)\n",
    "        self.final_bn = nn.BatchNorm2d(16)\n",
    "        self.final_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Encoder Stage 1\n",
    "        enc1 = self.enc1_conv(inputs)  # (B, start_fm, H, W)\n",
    "        B, C, H, W = enc1.shape\n",
    "        enc1_flat = enc1.view(B, C, H * W).permute(0, 2, 1)  # (B, N, C)\n",
    "        enc1_vig = self.enc1_vig(enc1_flat)\n",
    "        enc1 = enc1_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "        pool1 = self.pool1(enc1)\n",
    "\n",
    "        # Encoder Stage 2\n",
    "        enc2 = self.enc2_conv(pool1)\n",
    "        B, C, H, W = enc2.shape\n",
    "        enc2_flat = enc2.view(B, C, H * W).permute(0, 2, 1)\n",
    "        enc2_vig = self.enc2_vig(enc2_flat)\n",
    "        enc2 = enc2_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "        pool2 = self.pool2(enc2)\n",
    "\n",
    "        # Encoder Stage 3\n",
    "        enc3 = self.enc3_conv(pool2)\n",
    "        B, C, H, W = enc3.shape\n",
    "        enc3_flat = enc3.view(B, C, H * W).permute(0, 2, 1)\n",
    "        enc3_vig = self.enc3_vig(enc3_flat)\n",
    "        enc3 = enc3_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "        pool3 = self.pool3(enc3)\n",
    "\n",
    "        # Encoder Stage 4\n",
    "        enc4 = self.enc4_conv(pool3)\n",
    "        B, C, H, W = enc4.shape\n",
    "        enc4_flat = enc4.view(B, C, H * W).permute(0, 2, 1)\n",
    "        enc4_vig = self.enc4_vig(enc4_flat)\n",
    "        enc4 = enc4_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "        pool4 = self.pool4(enc4)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck_conv(pool4)\n",
    "        B, C, H, W = bottleneck.shape\n",
    "        bottleneck_flat = bottleneck.view(B, C, H * W).permute(0, 2, 1)\n",
    "        bottleneck_vig = self.bottleneck_vig(bottleneck_flat)\n",
    "        bottleneck = bottleneck_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Decoder Stage 4\n",
    "        up4 = self.up4(bottleneck)\n",
    "        cat4 = torch.cat([up4, enc4], dim=1)\n",
    "        dec4 = self.dec4_conv(cat4)\n",
    "        B, C, H, W = dec4.shape\n",
    "        dec4_flat = dec4.view(B, C, H * W).permute(0, 2, 1)\n",
    "        dec4_vig = self.dec4_vig(dec4_flat)\n",
    "        dec4 = dec4_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Decoder Stage 3\n",
    "        up3 = self.up3(dec4)\n",
    "        cat3 = torch.cat([up3, enc3], dim=1)\n",
    "        dec3 = self.dec3_conv(cat3)\n",
    "        B, C, H, W = dec3.shape\n",
    "        dec3_flat = dec3.view(B, C, H * W).permute(0, 2, 1)\n",
    "        dec3_vig = self.dec3_vig(dec3_flat)\n",
    "        dec3 = dec3_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Decoder Stage 2\n",
    "        up2 = self.up2(dec3)\n",
    "        cat2 = torch.cat([up2, enc2], dim=1)\n",
    "        dec2 = self.dec2_conv(cat2)\n",
    "        B, C, H, W = dec2.shape\n",
    "        dec2_flat = dec2.view(B, C, H * W).permute(0, 2, 1)\n",
    "        dec2_vig = self.dec2_vig(dec2_flat)\n",
    "        dec2 = dec2_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        # Decoder Stage 1\n",
    "        up1 = self.up1(dec2)\n",
    "        cat1 = torch.cat([up1, enc1], dim=1)\n",
    "        dec1 = self.dec1_conv(cat1)\n",
    "        B, C, H, W = dec1.shape\n",
    "        dec1_flat = dec1.view(B, C, H * W).permute(0, 2, 1)\n",
    "        dec1_vig = self.dec1_vig(dec1_flat)\n",
    "        dec1 = dec1_vig.permute(0, 2, 1).view(B, C, H, W)\n",
    "\n",
    "        out = self.final_conv(dec1)\n",
    "        out = self.final_bn(out)\n",
    "        out = self.final_act(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "Implements Dice loss for segmentation-based density reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dice(pred, target):\n",
    "    smooth = 1\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.reshape(num, -1)\n",
    "    m2 = target.reshape(num, -1)\n",
    "    intersection = m1 * m2\n",
    "    loss = (2. * intersection.sum(1) + smooth) / ((m1 * m1).sum(1) + (m2 * m2).sum(1) + smooth)\n",
    "    return loss.sum() / num\n",
    "\n",
    "def my_loss(pre_y, tru_y):\n",
    "    loss = 1 - dice(pre_y, tru_y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading and Preprocessing\n",
    "\n",
    "Loads gravity anomaly data and corresponding density models.\n",
    "Prepares PyTorch Dataset and DataLoader objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folders\n",
    "dataFile = './data/tra&val/data{}.mat'\n",
    "syn_dataFile = './data/syn/data{}.mat'\n",
    "\n",
    "# For creating the forward response\n",
    "with h5py.File(name='./G.mat', mode='r') as f:G = torch.Tensor(np.nan_to_num(f['G'][:])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(total_num):\n",
    "    data = h5py.File(dataFile.format(i), 'r')\n",
    "    m = data['m'][0] / density\n",
    "    d = data['d'][0]\n",
    "    d = np.nan_to_num(d)\n",
    "    x.append(d.reshape(1, num_cell, num_cell))\n",
    "    y.append(m.reshape(16, num_cell, num_cell))\n",
    "\n",
    "syn_x = []\n",
    "syn_y = []\n",
    "for i in range(syn_num):\n",
    "    data = h5py.File(syn_dataFile.format(i), 'r')\n",
    "    m = data['m'][0] / density\n",
    "    d = data['d'][0]\n",
    "    d = np.nan_to_num(d)\n",
    "    syn_x.append(d.reshape(1, num_cell, num_cell))\n",
    "    syn_y.append(m.reshape(16, num_cell, num_cell))\n",
    "\n",
    "tra_x = x[:tra_num]\n",
    "tra_y = y[:tra_num]\n",
    "val_x = x[-val_num:]\n",
    "val_y = y[-val_num:]\n",
    "\n",
    "\n",
    "print(np.shape(tra_x), \"::\", np.shape(tra_y))\n",
    "print(np.shape(val_x), \"::\", np.shape(val_y))\n",
    "print(np.shape(syn_x), \"::\", np.shape(syn_y))\n",
    "\n",
    "tra_idxs = list(range(len(tra_x)))\n",
    "val_idxs = list(range(len(val_x)))\n",
    "# np.random.shuffle(tra_idxs)\n",
    "# np.random.shuffle(val_idxs)\n",
    "syn_idxs = list(range(len(syn_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, train=True, masks=None):\n",
    "        self.train = train\n",
    "        self.images = images\n",
    "        if self.train:\n",
    "            self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = None\n",
    "        if self.train:\n",
    "            mask = self.masks[idx]\n",
    "        return (image, mask)\n",
    "\n",
    "\n",
    "tra = Dataset(np.array(tra_x).astype(np.float32)[tra_idxs], train=True,\n",
    "              masks=np.array(tra_y).astype(np.float32)[tra_idxs])\n",
    "val = Dataset(np.array(val_x).astype(np.float32)[val_idxs], train=True,\n",
    "              masks=np.array(val_y).astype(np.float32)[val_idxs])\n",
    "syn = Dataset(np.array(syn_x).astype(np.float32)[syn_idxs], train=True,\n",
    "              masks=np.array(syn_y).astype(np.float32)[syn_idxs])\n",
    "\n",
    "tra_loader = torch.utils.data.DataLoader(dataset=tra, batch_size=batch_size, shuffle=False, pin_memory=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batch_size, shuffle=False, pin_memory=False)\n",
    "syn_loader = torch.utils.data.DataLoader(dataset=syn, batch_size=batch_size, shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             320\n",
      "               ELU-2           [-1, 32, 32, 32]               0\n",
      "            Conv2d-3           [-1, 32, 32, 32]           9,248\n",
      "       double_conv-4           [-1, 32, 32, 32]               0\n",
      "            Linear-5             [-1, 1024, 32]           1,056\n",
      "            Linear-6              [-1, 1024, 8]             520\n",
      "            Linear-7              [-1, 1024, 8]             520\n",
      "            Linear-8              [-1, 1024, 8]             520\n",
      "            Linear-9              [-1, 1024, 8]             520\n",
      "        GraphConv-10             [-1, 1024, 32]               0\n",
      "           Linear-11             [-1, 1024, 32]           1,056\n",
      "             ReLU-12             [-1, 1024, 32]               0\n",
      "          Dropout-13             [-1, 1024, 32]               0\n",
      "        LayerNorm-14             [-1, 1024, 32]              64\n",
      "           Linear-15             [-1, 1024, 64]           2,112\n",
      "             ReLU-16             [-1, 1024, 64]               0\n",
      "           Linear-17             [-1, 1024, 32]           2,080\n",
      "          Dropout-18             [-1, 1024, 32]               0\n",
      "        LayerNorm-19             [-1, 1024, 32]              64\n",
      "         ViGBlock-20             [-1, 1024, 32]               0\n",
      "        MaxPool2d-21           [-1, 32, 16, 16]               0\n",
      "           Conv2d-22           [-1, 64, 16, 16]          18,496\n",
      "              ELU-23           [-1, 64, 16, 16]               0\n",
      "           Conv2d-24           [-1, 64, 16, 16]          36,928\n",
      "      double_conv-25           [-1, 64, 16, 16]               0\n",
      "           Linear-26              [-1, 256, 64]           4,160\n",
      "           Linear-27              [-1, 256, 16]           2,064\n",
      "           Linear-28              [-1, 256, 16]           2,064\n",
      "           Linear-29              [-1, 256, 16]           2,064\n",
      "           Linear-30              [-1, 256, 16]           2,064\n",
      "        GraphConv-31              [-1, 256, 64]               0\n",
      "           Linear-32              [-1, 256, 64]           4,160\n",
      "             ReLU-33              [-1, 256, 64]               0\n",
      "          Dropout-34              [-1, 256, 64]               0\n",
      "        LayerNorm-35              [-1, 256, 64]             128\n",
      "           Linear-36             [-1, 256, 128]           8,320\n",
      "             ReLU-37             [-1, 256, 128]               0\n",
      "           Linear-38              [-1, 256, 64]           8,256\n",
      "          Dropout-39              [-1, 256, 64]               0\n",
      "        LayerNorm-40              [-1, 256, 64]             128\n",
      "         ViGBlock-41              [-1, 256, 64]               0\n",
      "        MaxPool2d-42             [-1, 64, 8, 8]               0\n",
      "           Conv2d-43            [-1, 128, 8, 8]          73,856\n",
      "              ELU-44            [-1, 128, 8, 8]               0\n",
      "           Conv2d-45            [-1, 128, 8, 8]         147,584\n",
      "      double_conv-46            [-1, 128, 8, 8]               0\n",
      "           Linear-47              [-1, 64, 128]          16,512\n",
      "           Linear-48               [-1, 64, 32]           8,224\n",
      "           Linear-49               [-1, 64, 32]           8,224\n",
      "           Linear-50               [-1, 64, 32]           8,224\n",
      "           Linear-51               [-1, 64, 32]           8,224\n",
      "        GraphConv-52              [-1, 64, 128]               0\n",
      "           Linear-53              [-1, 64, 128]          16,512\n",
      "             ReLU-54              [-1, 64, 128]               0\n",
      "          Dropout-55              [-1, 64, 128]               0\n",
      "        LayerNorm-56              [-1, 64, 128]             256\n",
      "           Linear-57              [-1, 64, 256]          33,024\n",
      "             ReLU-58              [-1, 64, 256]               0\n",
      "           Linear-59              [-1, 64, 128]          32,896\n",
      "          Dropout-60              [-1, 64, 128]               0\n",
      "        LayerNorm-61              [-1, 64, 128]             256\n",
      "         ViGBlock-62              [-1, 64, 128]               0\n",
      "        MaxPool2d-63            [-1, 128, 4, 4]               0\n",
      "           Conv2d-64            [-1, 256, 4, 4]         295,168\n",
      "              ELU-65            [-1, 256, 4, 4]               0\n",
      "           Conv2d-66            [-1, 256, 4, 4]         590,080\n",
      "      double_conv-67            [-1, 256, 4, 4]               0\n",
      "           Linear-68              [-1, 16, 256]          65,792\n",
      "           Linear-69               [-1, 16, 64]          32,832\n",
      "           Linear-70               [-1, 16, 64]          32,832\n",
      "           Linear-71               [-1, 16, 64]          32,832\n",
      "           Linear-72               [-1, 16, 64]          32,832\n",
      "        GraphConv-73              [-1, 16, 256]               0\n",
      "           Linear-74              [-1, 16, 256]          65,792\n",
      "             ReLU-75              [-1, 16, 256]               0\n",
      "          Dropout-76              [-1, 16, 256]               0\n",
      "        LayerNorm-77              [-1, 16, 256]             512\n",
      "           Linear-78              [-1, 16, 512]         131,584\n",
      "             ReLU-79              [-1, 16, 512]               0\n",
      "           Linear-80              [-1, 16, 256]         131,328\n",
      "          Dropout-81              [-1, 16, 256]               0\n",
      "        LayerNorm-82              [-1, 16, 256]             512\n",
      "         ViGBlock-83              [-1, 16, 256]               0\n",
      "        MaxPool2d-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85            [-1, 512, 2, 2]       1,180,160\n",
      "              ELU-86            [-1, 512, 2, 2]               0\n",
      "           Conv2d-87            [-1, 512, 2, 2]       2,359,808\n",
      "      double_conv-88            [-1, 512, 2, 2]               0\n",
      "           Linear-89               [-1, 4, 512]         262,656\n",
      "           Linear-90               [-1, 4, 128]         131,200\n",
      "           Linear-91               [-1, 4, 128]         131,200\n",
      "           Linear-92               [-1, 4, 128]         131,200\n",
      "           Linear-93               [-1, 4, 128]         131,200\n",
      "        GraphConv-94               [-1, 4, 512]               0\n",
      "           Linear-95               [-1, 4, 512]         262,656\n",
      "             ReLU-96               [-1, 4, 512]               0\n",
      "          Dropout-97               [-1, 4, 512]               0\n",
      "        LayerNorm-98               [-1, 4, 512]           1,024\n",
      "           Linear-99              [-1, 4, 1024]         525,312\n",
      "            ReLU-100              [-1, 4, 1024]               0\n",
      "          Linear-101               [-1, 4, 512]         524,800\n",
      "         Dropout-102               [-1, 4, 512]               0\n",
      "       LayerNorm-103               [-1, 4, 512]           1,024\n",
      "        ViGBlock-104               [-1, 4, 512]               0\n",
      " ConvTranspose2d-105            [-1, 256, 4, 4]         524,544\n",
      "          Conv2d-106            [-1, 256, 4, 4]       1,179,904\n",
      "             ELU-107            [-1, 256, 4, 4]               0\n",
      "          Conv2d-108            [-1, 256, 4, 4]         590,080\n",
      "     double_conv-109            [-1, 256, 4, 4]               0\n",
      "          Linear-110              [-1, 16, 256]          65,792\n",
      "          Linear-111               [-1, 16, 64]          32,832\n",
      "          Linear-112               [-1, 16, 64]          32,832\n",
      "          Linear-113               [-1, 16, 64]          32,832\n",
      "          Linear-114               [-1, 16, 64]          32,832\n",
      "       GraphConv-115              [-1, 16, 256]               0\n",
      "          Linear-116              [-1, 16, 256]          65,792\n",
      "            ReLU-117              [-1, 16, 256]               0\n",
      "         Dropout-118              [-1, 16, 256]               0\n",
      "       LayerNorm-119              [-1, 16, 256]             512\n",
      "          Linear-120              [-1, 16, 512]         131,584\n",
      "            ReLU-121              [-1, 16, 512]               0\n",
      "          Linear-122              [-1, 16, 256]         131,328\n",
      "         Dropout-123              [-1, 16, 256]               0\n",
      "       LayerNorm-124              [-1, 16, 256]             512\n",
      "        ViGBlock-125              [-1, 16, 256]               0\n",
      " ConvTranspose2d-126            [-1, 128, 8, 8]         131,200\n",
      "          Conv2d-127            [-1, 128, 8, 8]         295,040\n",
      "             ELU-128            [-1, 128, 8, 8]               0\n",
      "          Conv2d-129            [-1, 128, 8, 8]         147,584\n",
      "     double_conv-130            [-1, 128, 8, 8]               0\n",
      "          Linear-131              [-1, 64, 128]          16,512\n",
      "          Linear-132               [-1, 64, 32]           8,224\n",
      "          Linear-133               [-1, 64, 32]           8,224\n",
      "          Linear-134               [-1, 64, 32]           8,224\n",
      "          Linear-135               [-1, 64, 32]           8,224\n",
      "       GraphConv-136              [-1, 64, 128]               0\n",
      "          Linear-137              [-1, 64, 128]          16,512\n",
      "            ReLU-138              [-1, 64, 128]               0\n",
      "         Dropout-139              [-1, 64, 128]               0\n",
      "       LayerNorm-140              [-1, 64, 128]             256\n",
      "          Linear-141              [-1, 64, 256]          33,024\n",
      "            ReLU-142              [-1, 64, 256]               0\n",
      "          Linear-143              [-1, 64, 128]          32,896\n",
      "         Dropout-144              [-1, 64, 128]               0\n",
      "       LayerNorm-145              [-1, 64, 128]             256\n",
      "        ViGBlock-146              [-1, 64, 128]               0\n",
      " ConvTranspose2d-147           [-1, 64, 16, 16]          32,832\n",
      "          Conv2d-148           [-1, 64, 16, 16]          73,792\n",
      "             ELU-149           [-1, 64, 16, 16]               0\n",
      "          Conv2d-150           [-1, 64, 16, 16]          36,928\n",
      "     double_conv-151           [-1, 64, 16, 16]               0\n",
      "          Linear-152              [-1, 256, 64]           4,160\n",
      "          Linear-153              [-1, 256, 16]           2,064\n",
      "          Linear-154              [-1, 256, 16]           2,064\n",
      "          Linear-155              [-1, 256, 16]           2,064\n",
      "          Linear-156              [-1, 256, 16]           2,064\n",
      "       GraphConv-157              [-1, 256, 64]               0\n",
      "          Linear-158              [-1, 256, 64]           4,160\n",
      "            ReLU-159              [-1, 256, 64]               0\n",
      "         Dropout-160              [-1, 256, 64]               0\n",
      "       LayerNorm-161              [-1, 256, 64]             128\n",
      "          Linear-162             [-1, 256, 128]           8,320\n",
      "            ReLU-163             [-1, 256, 128]               0\n",
      "          Linear-164              [-1, 256, 64]           8,256\n",
      "         Dropout-165              [-1, 256, 64]               0\n",
      "       LayerNorm-166              [-1, 256, 64]             128\n",
      "        ViGBlock-167              [-1, 256, 64]               0\n",
      " ConvTranspose2d-168           [-1, 32, 32, 32]           8,224\n",
      "          Conv2d-169           [-1, 32, 32, 32]          18,464\n",
      "             ELU-170           [-1, 32, 32, 32]               0\n",
      "          Conv2d-171           [-1, 32, 32, 32]           9,248\n",
      "     double_conv-172           [-1, 32, 32, 32]               0\n",
      "          Linear-173             [-1, 1024, 32]           1,056\n",
      "          Linear-174              [-1, 1024, 8]             520\n",
      "          Linear-175              [-1, 1024, 8]             520\n",
      "          Linear-176              [-1, 1024, 8]             520\n",
      "          Linear-177              [-1, 1024, 8]             520\n",
      "       GraphConv-178             [-1, 1024, 32]               0\n",
      "          Linear-179             [-1, 1024, 32]           1,056\n",
      "            ReLU-180             [-1, 1024, 32]               0\n",
      "         Dropout-181             [-1, 1024, 32]               0\n",
      "       LayerNorm-182             [-1, 1024, 32]              64\n",
      "          Linear-183             [-1, 1024, 64]           2,112\n",
      "            ReLU-184             [-1, 1024, 64]               0\n",
      "          Linear-185             [-1, 1024, 32]           2,080\n",
      "         Dropout-186             [-1, 1024, 32]               0\n",
      "       LayerNorm-187             [-1, 1024, 32]              64\n",
      "        ViGBlock-188             [-1, 1024, 32]               0\n",
      "          Conv2d-189           [-1, 16, 32, 32]             528\n",
      "     BatchNorm2d-190           [-1, 16, 32, 32]              32\n",
      "         Sigmoid-191           [-1, 16, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 11,264,560\n",
      "Trainable params: 11,264,560\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 19.07\n",
      "Params size (MB): 42.97\n",
      "Estimated Total Size (MB): 62.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ViGUNet(start_fm=32, num_heads=4, dropout=0.3, k=8)\n",
    "model.cuda()\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Summarize the model with a sample input size (1, 32, 32)\n",
    "summary(model, input_size=(1, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation, and Testing Loop\n",
    "\n",
    "This block performs the complete model training procedure:\n",
    "\n",
    "- **Training phase:**  \n",
    "  The model is set to training mode, performs forward propagation on training data, computes loss, backpropagates gradients, and updates parameters.\n",
    "\n",
    "- **Validation phase:**  \n",
    "  The model switches to evaluation mode. Validation loss is computed without gradient updates. Early stopping is checked based on validation loss stability.\n",
    "\n",
    "- **Synthetic test phase:**  \n",
    "  The model is evaluated on synthetic geological models to assess generalization performance.\n",
    "\n",
    "- **Checkpointing:**  \n",
    "  Model weights are saved at the end of every epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at the end of epoch 0.\n",
      "Epoch: 1. Tra Loss: 0.7983. Val Loss: 0.7338. Syn Loss: 0.7109\n",
      "Model saved at the end of epoch 1.\n",
      "Epoch: 2. Tra Loss: 0.6681. Val Loss: 0.5605. Syn Loss: 0.5330\n",
      "Model saved at the end of epoch 2.\n",
      "Epoch: 3. Tra Loss: 0.5411. Val Loss: 0.5035. Syn Loss: 0.4436\n",
      "Model saved at the end of epoch 3.\n",
      "Epoch: 4. Tra Loss: 0.4320. Val Loss: 0.3863. Syn Loss: 0.3190\n",
      "Model saved at the end of epoch 4.\n",
      "Epoch: 5. Tra Loss: 0.3582. Val Loss: 0.3314. Syn Loss: 0.2670\n",
      "Model saved at the end of epoch 5.\n",
      "Epoch: 6. Tra Loss: 0.3187. Val Loss: 0.3013. Syn Loss: 0.2600\n",
      "Model saved at the end of epoch 6.\n",
      "Epoch: 7. Tra Loss: 0.2946. Val Loss: 0.2858. Syn Loss: 0.2244\n",
      "Model saved at the end of epoch 7.\n",
      "Epoch: 8. Tra Loss: 0.2793. Val Loss: 0.2685. Syn Loss: 0.2025\n",
      "Model saved at the end of epoch 8.\n",
      "Epoch: 9. Tra Loss: 0.2681. Val Loss: 0.2611. Syn Loss: 0.1910\n",
      "Model saved at the end of epoch 9.\n",
      "Epoch: 10. Tra Loss: 0.2600. Val Loss: 0.2495. Syn Loss: 0.1788\n",
      "Model saved at the end of epoch 10.\n",
      "Epoch: 11. Tra Loss: 0.2527. Val Loss: 0.2474. Syn Loss: 0.1715\n",
      "Model saved at the end of epoch 11.\n",
      "Epoch: 12. Tra Loss: 0.2468. Val Loss: 0.2401. Syn Loss: 0.1643\n",
      "Model saved at the end of epoch 12.\n",
      "Epoch: 13. Tra Loss: 0.2426. Val Loss: 0.2373. Syn Loss: 0.1607\n",
      "Model saved at the end of epoch 13.\n",
      "Epoch: 14. Tra Loss: 0.2374. Val Loss: 0.2303. Syn Loss: 0.1524\n",
      "Model saved at the end of epoch 14.\n",
      "Epoch: 15. Tra Loss: 0.2339. Val Loss: 0.2287. Syn Loss: 0.1538\n",
      "Model saved at the end of epoch 15.\n",
      "Epoch: 16. Tra Loss: 0.2297. Val Loss: 0.2252. Syn Loss: 0.1474\n",
      "Model saved at the end of epoch 16.\n",
      "Epoch: 17. Tra Loss: 0.2248. Val Loss: 0.2209. Syn Loss: 0.1489\n",
      "Model saved at the end of epoch 17.\n",
      "Epoch: 18. Tra Loss: 0.2173. Val Loss: 0.2139. Syn Loss: 0.1426\n",
      "Model saved at the end of epoch 18.\n",
      "Epoch: 19. Tra Loss: 0.2127. Val Loss: 0.2117. Syn Loss: 0.1403\n",
      "Model saved at the end of epoch 19.\n",
      "Epoch: 20. Tra Loss: 0.2091. Val Loss: 0.2108. Syn Loss: 0.1360\n",
      "Model saved at the end of epoch 20.\n",
      "Epoch: 21. Tra Loss: 0.2060. Val Loss: 0.2074. Syn Loss: 0.1375\n",
      "Model saved at the end of epoch 21.\n",
      "Epoch: 22. Tra Loss: 0.2033. Val Loss: 0.2049. Syn Loss: 0.1343\n",
      "Model saved at the end of epoch 22.\n",
      "Epoch: 23. Tra Loss: 0.2009. Val Loss: 0.2059. Syn Loss: 0.1359\n",
      "Model saved at the end of epoch 23.\n",
      "Epoch: 24. Tra Loss: 0.1985. Val Loss: 0.2036. Syn Loss: 0.1357\n",
      "Model saved at the end of epoch 24.\n",
      "Epoch: 25. Tra Loss: 0.1965. Val Loss: 0.2015. Syn Loss: 0.1325\n",
      "Model saved at the end of epoch 25.\n",
      "Epoch: 26. Tra Loss: 0.1950. Val Loss: 0.2025. Syn Loss: 0.1304\n",
      "Model saved at the end of epoch 26.\n",
      "Epoch: 27. Tra Loss: 0.1932. Val Loss: 0.2030. Syn Loss: 0.1307\n",
      "Model saved at the end of epoch 27.\n",
      "Epoch: 28. Tra Loss: 0.1918. Val Loss: 0.2014. Syn Loss: 0.1267\n",
      "Model saved at the end of epoch 28.\n",
      "Epoch: 29. Tra Loss: 0.1901. Val Loss: 0.1988. Syn Loss: 0.1245\n",
      "Model saved at the end of epoch 29.\n",
      "Epoch: 30. Tra Loss: 0.1889. Val Loss: 0.1989. Syn Loss: 0.1247\n",
      "Model saved at the end of epoch 30.\n",
      "Epoch: 31. Tra Loss: 0.1878. Val Loss: 0.1970. Syn Loss: 0.1206\n",
      "Model saved at the end of epoch 31.\n",
      "Epoch: 32. Tra Loss: 0.1865. Val Loss: 0.1963. Syn Loss: 0.1167\n",
      "Model saved at the end of epoch 32.\n",
      "Epoch: 33. Tra Loss: 0.1850. Val Loss: 0.1939. Syn Loss: 0.1128\n",
      "Model saved at the end of epoch 33.\n",
      "Epoch: 34. Tra Loss: 0.1845. Val Loss: 0.1960. Syn Loss: 0.1196\n",
      "Model saved at the end of epoch 34.\n",
      "Epoch: 35. Tra Loss: 0.1829. Val Loss: 0.1960. Syn Loss: 0.1179\n",
      "Model saved at the end of epoch 35.\n",
      "Epoch: 36. Tra Loss: 0.1814. Val Loss: 0.1939. Syn Loss: 0.1173\n",
      "Model saved at the end of epoch 36.\n",
      "Epoch: 37. Tra Loss: 0.1802. Val Loss: 0.1948. Syn Loss: 0.1172\n",
      "Model saved at the end of epoch 37.\n",
      "Epoch: 38. Tra Loss: 0.1791. Val Loss: 0.1936. Syn Loss: 0.1107\n",
      "Model saved at the end of epoch 38.\n",
      "Epoch: 39. Tra Loss: 0.1784. Val Loss: 0.1932. Syn Loss: 0.1091\n",
      "Model saved at the end of epoch 39.\n",
      "Epoch: 40. Tra Loss: 0.1775. Val Loss: 0.1927. Syn Loss: 0.1100\n",
      "Model saved at the end of epoch 40.\n",
      "Epoch: 41. Tra Loss: 0.1762. Val Loss: 0.1923. Syn Loss: 0.1064\n",
      "Model saved at the end of epoch 41.\n",
      "Epoch: 42. Tra Loss: 0.1757. Val Loss: 0.1924. Syn Loss: 0.1079\n",
      "Model saved at the end of epoch 42.\n",
      "Epoch: 43. Tra Loss: 0.1740. Val Loss: 0.1931. Syn Loss: 0.1085\n",
      "Model saved at the end of epoch 43.\n",
      "Epoch: 44. Tra Loss: 0.1733. Val Loss: 0.1925. Syn Loss: 0.1082\n",
      "Model saved at the end of epoch 44.\n",
      "Epoch: 45. Tra Loss: 0.1724. Val Loss: 0.1937. Syn Loss: 0.1124\n",
      "Model saved at the end of epoch 45.\n",
      "Epoch: 46. Tra Loss: 0.1716. Val Loss: 0.1951. Syn Loss: 0.1093\n",
      "Model saved at the end of epoch 46.\n",
      "Epoch: 47. Tra Loss: 0.1705. Val Loss: 0.1966. Syn Loss: 0.1189\n",
      "Model saved at the end of epoch 47.\n",
      "Epoch: 48. Tra Loss: 0.1699. Val Loss: 0.1939. Syn Loss: 0.1107\n",
      "Model saved at the end of epoch 48.\n",
      "Epoch: 49. Tra Loss: 0.1689. Val Loss: 0.1949. Syn Loss: 0.1118\n",
      "Model saved at the end of epoch 49.\n",
      "Epoch: 50. Tra Loss: 0.1672. Val Loss: 0.1961. Syn Loss: 0.1155\n",
      "Model saved at the end of epoch 50.\n",
      "Epoch: 51. Tra Loss: 0.1662. Val Loss: 0.1946. Syn Loss: 0.1135\n",
      "Model saved at the end of epoch 51.\n",
      "Epoch: 52. Tra Loss: 0.1654. Val Loss: 0.1943. Syn Loss: 0.1191\n",
      "Model saved at the end of epoch 52.\n",
      "Epoch: 53. Tra Loss: 0.1648. Val Loss: 0.1926. Syn Loss: 0.1084\n",
      "Model saved at the end of epoch 53.\n",
      "Epoch: 54. Tra Loss: 0.1641. Val Loss: 0.1939. Syn Loss: 0.1162\n",
      "Model saved at the end of epoch 54.\n",
      "Epoch: 55. Tra Loss: 0.1630. Val Loss: 0.1953. Syn Loss: 0.1165\n",
      "Model saved at the end of epoch 55.\n",
      "Epoch: 56. Tra Loss: 0.1622. Val Loss: 0.1936. Syn Loss: 0.1160\n",
      "Model saved at the end of epoch 56.\n",
      "Epoch: 57. Tra Loss: 0.1609. Val Loss: 0.1927. Syn Loss: 0.1108\n",
      "Model saved at the end of epoch 57.\n",
      "Epoch: 58. Tra Loss: 0.1602. Val Loss: 0.1949. Syn Loss: 0.1137\n",
      "Model saved at the end of epoch 58.\n",
      "Epoch: 59. Tra Loss: 0.1593. Val Loss: 0.1947. Syn Loss: 0.1126\n",
      "Model saved at the end of epoch 59.\n",
      "Epoch: 60. Tra Loss: 0.1587. Val Loss: 0.1966. Syn Loss: 0.1146\n",
      "Model saved at the end of epoch 60.\n",
      "Epoch: 61. Tra Loss: 0.1577. Val Loss: 0.1946. Syn Loss: 0.1078\n",
      "Model saved at the end of epoch 61.\n",
      "Epoch: 62. Tra Loss: 0.1569. Val Loss: 0.1949. Syn Loss: 0.1157\n",
      "Model saved at the end of epoch 62.\n",
      "Epoch: 63. Tra Loss: 0.1561. Val Loss: 0.1944. Syn Loss: 0.1123\n",
      "Model saved at the end of epoch 63.\n",
      "Epoch: 64. Tra Loss: 0.1550. Val Loss: 0.1928. Syn Loss: 0.1138\n",
      "Model saved at the end of epoch 64.\n",
      "Epoch: 65. Tra Loss: 0.1542. Val Loss: 0.1941. Syn Loss: 0.1139\n",
      "Model saved at the end of epoch 65.\n",
      "Epoch: 66. Tra Loss: 0.1541. Val Loss: 0.1934. Syn Loss: 0.1187\n",
      "Model saved at the end of epoch 66.\n",
      "Epoch: 67. Tra Loss: 0.1531. Val Loss: 0.1955. Syn Loss: 0.1173\n",
      "Model saved at the end of epoch 67.\n",
      "Epoch: 68. Tra Loss: 0.1523. Val Loss: 0.1926. Syn Loss: 0.1147\n",
      "Model saved at the end of epoch 68.\n",
      "Epoch: 69. Tra Loss: 0.1516. Val Loss: 0.1918. Syn Loss: 0.1079\n",
      "Model saved at the end of epoch 69.\n",
      "Epoch: 70. Tra Loss: 0.1503. Val Loss: 0.1930. Syn Loss: 0.1139\n",
      "Model saved at the end of epoch 70.\n",
      "Epoch: 71. Tra Loss: 0.1493. Val Loss: 0.1940. Syn Loss: 0.1126\n",
      "Model saved at the end of epoch 71.\n",
      "Epoch: 72. Tra Loss: 0.1481. Val Loss: 0.1960. Syn Loss: 0.1124\n",
      "Model saved at the end of epoch 72.\n",
      "Epoch: 73. Tra Loss: 0.1473. Val Loss: 0.1944. Syn Loss: 0.1187\n",
      "Model saved at the end of epoch 73.\n",
      "Epoch: 74. Tra Loss: 0.1463. Val Loss: 0.1930. Syn Loss: 0.1110\n",
      "Model saved at the end of epoch 74.\n",
      "Epoch: 75. Tra Loss: 0.1458. Val Loss: 0.1945. Syn Loss: 0.1118\n",
      "Model saved at the end of epoch 75.\n",
      "Epoch: 76. Tra Loss: 0.1451. Val Loss: 0.1967. Syn Loss: 0.1116\n",
      "Model saved at the end of epoch 76.\n",
      "Epoch: 77. Tra Loss: 0.1444. Val Loss: 0.1972. Syn Loss: 0.1135\n",
      "Model saved at the end of epoch 77.\n",
      "Epoch: 78. Tra Loss: 0.1445. Val Loss: 0.2010. Syn Loss: 0.1175\n",
      "Model saved at the end of epoch 78.\n",
      "Epoch: 79. Tra Loss: 0.1439. Val Loss: 0.1970. Syn Loss: 0.1147\n",
      "Model saved at the end of epoch 79.\n",
      "Epoch: 80. Tra Loss: 0.1433. Val Loss: 0.1992. Syn Loss: 0.1114\n",
      "Model saved at the end of epoch 80.\n",
      "Epoch: 81. Tra Loss: 0.1431. Val Loss: 0.1980. Syn Loss: 0.1135\n",
      "Model saved at the end of epoch 81.\n",
      "Epoch: 82. Tra Loss: 0.1417. Val Loss: 0.1988. Syn Loss: 0.1146\n",
      "Model saved at the end of epoch 82.\n",
      "Epoch: 83. Tra Loss: 0.1414. Val Loss: 0.1981. Syn Loss: 0.1130\n",
      "Model saved at the end of epoch 83.\n",
      "Epoch: 84. Tra Loss: 0.1409. Val Loss: 0.1966. Syn Loss: 0.1105\n",
      "Model saved at the end of epoch 84.\n",
      "Epoch: 85. Tra Loss: 0.1404. Val Loss: 0.1985. Syn Loss: 0.1117\n",
      "Model saved at the end of epoch 85.\n",
      "Epoch: 86. Tra Loss: 0.1395. Val Loss: 0.1955. Syn Loss: 0.1074\n",
      "Model saved at the end of epoch 86.\n",
      "Epoch: 87. Tra Loss: 0.1390. Val Loss: 0.1933. Syn Loss: 0.1070\n",
      "Model saved at the end of epoch 87.\n",
      "Epoch: 88. Tra Loss: 0.1392. Val Loss: 0.1947. Syn Loss: 0.1061\n",
      "Model saved at the end of epoch 88.\n",
      "Epoch: 89. Tra Loss: 0.1379. Val Loss: 0.1926. Syn Loss: 0.1104\n",
      "Model saved at the end of epoch 89.\n",
      "Epoch: 90. Tra Loss: 0.1368. Val Loss: 0.1938. Syn Loss: 0.1045\n",
      "Model saved at the end of epoch 90.\n",
      "Epoch: 91. Tra Loss: 0.1360. Val Loss: 0.1931. Syn Loss: 0.1062\n",
      "Model saved at the end of epoch 91.\n",
      "Epoch: 92. Tra Loss: 0.1357. Val Loss: 0.1946. Syn Loss: 0.1080\n",
      "Model saved at the end of epoch 92.\n",
      "Epoch: 93. Tra Loss: 0.1357. Val Loss: 0.1964. Syn Loss: 0.1116\n",
      "Model saved at the end of epoch 93.\n",
      "Epoch: 94. Tra Loss: 0.1350. Val Loss: 0.1993. Syn Loss: 0.1114\n",
      "Model saved at the end of epoch 94.\n",
      "Epoch: 95. Tra Loss: 0.1345. Val Loss: 0.1985. Syn Loss: 0.1122\n",
      "Model saved at the end of epoch 95.\n",
      "Epoch: 96. Tra Loss: 0.1342. Val Loss: 0.1997. Syn Loss: 0.1112\n",
      "Model saved at the end of epoch 96.\n",
      "Epoch: 97. Tra Loss: 0.1337. Val Loss: 0.1967. Syn Loss: 0.1115\n",
      "Model saved at the end of epoch 97.\n",
      "Epoch: 98. Tra Loss: 0.1331. Val Loss: 0.1962. Syn Loss: 0.1085\n",
      "Model saved at the end of epoch 98.\n",
      "Epoch: 99. Tra Loss: 0.1325. Val Loss: 0.1999. Syn Loss: 0.1125\n",
      "Model saved at the end of epoch 99.\n",
      "Epoch: 100. Tra Loss: 0.1313. Val Loss: 0.1992. Syn Loss: 0.1116\n",
      "Model saved at the end of epoch 100.\n",
      "Epoch: 101. Tra Loss: 0.1307. Val Loss: 0.1976. Syn Loss: 0.1099\n",
      "Model saved at the end of epoch 101.\n",
      "Epoch: 102. Tra Loss: 0.1295. Val Loss: 0.2008. Syn Loss: 0.1138\n",
      "Model saved at the end of epoch 102.\n",
      "Epoch: 103. Tra Loss: 0.1294. Val Loss: 0.1980. Syn Loss: 0.1125\n",
      "Model saved at the end of epoch 103.\n",
      "Epoch: 104. Tra Loss: 0.1289. Val Loss: 0.1998. Syn Loss: 0.1113\n",
      "Model saved at the end of epoch 104.\n",
      "Epoch: 105. Tra Loss: 0.1286. Val Loss: 0.1991. Syn Loss: 0.1133\n",
      "Model saved at the end of epoch 105.\n",
      "Epoch: 106. Tra Loss: 0.1287. Val Loss: 0.2025. Syn Loss: 0.1141\n",
      "Model saved at the end of epoch 106.\n",
      "Epoch: 107. Tra Loss: 0.1281. Val Loss: 0.1969. Syn Loss: 0.1138\n",
      "Model saved at the end of epoch 107.\n",
      "Epoch: 108. Tra Loss: 0.1279. Val Loss: 0.1985. Syn Loss: 0.1096\n",
      "Model saved at the end of epoch 108.\n",
      "Epoch: 109. Tra Loss: 0.1278. Val Loss: 0.1998. Syn Loss: 0.1156\n",
      "Model saved at the end of epoch 109.\n",
      "Epoch: 110. Tra Loss: 0.1280. Val Loss: 0.2007. Syn Loss: 0.1132\n",
      "Model saved at the end of epoch 110.\n",
      "Epoch: 111. Tra Loss: 0.1269. Val Loss: 0.2024. Syn Loss: 0.1150\n",
      "Model saved at the end of epoch 111.\n",
      "Epoch: 112. Tra Loss: 0.1260. Val Loss: 0.2012. Syn Loss: 0.1172\n",
      "Model saved at the end of epoch 112.\n",
      "Epoch: 113. Tra Loss: 0.1255. Val Loss: 0.2012. Syn Loss: 0.1133\n",
      "Model saved at the end of epoch 113.\n",
      "Epoch: 114. Tra Loss: 0.1246. Val Loss: 0.1987. Syn Loss: 0.1102\n",
      "Model saved at the end of epoch 114.\n",
      "Epoch: 115. Tra Loss: 0.1241. Val Loss: 0.2007. Syn Loss: 0.1150\n",
      "Model saved at the end of epoch 115.\n",
      "Epoch: 116. Tra Loss: 0.1234. Val Loss: 0.2007. Syn Loss: 0.1162\n",
      "Model saved at the end of epoch 116.\n",
      "Epoch: 117. Tra Loss: 0.1230. Val Loss: 0.2003. Syn Loss: 0.1126\n",
      "Model saved at the end of epoch 117.\n",
      "Epoch: 118. Tra Loss: 0.1225. Val Loss: 0.2018. Syn Loss: 0.1161\n",
      "Model saved at the end of epoch 118.\n",
      "Epoch: 119. Tra Loss: 0.1224. Val Loss: 0.2029. Syn Loss: 0.1196\n",
      "Model saved at the end of epoch 119.\n",
      "Epoch: 120. Tra Loss: 0.1218. Val Loss: 0.2030. Syn Loss: 0.1186\n",
      "Model saved at the end of epoch 120.\n",
      "Epoch: 121. Tra Loss: 0.1218. Val Loss: 0.2042. Syn Loss: 0.1203\n",
      "Model saved at the end of epoch 121.\n",
      "Epoch: 122. Tra Loss: 0.1211. Val Loss: 0.2016. Syn Loss: 0.1220\n",
      "Model saved at the end of epoch 122.\n",
      "Epoch: 123. Tra Loss: 0.1208. Val Loss: 0.2059. Syn Loss: 0.1245\n",
      "Model saved at the end of epoch 123.\n",
      "Epoch: 124. Tra Loss: 0.1207. Val Loss: 0.2039. Syn Loss: 0.1166\n",
      "Model saved at the end of epoch 124.\n",
      "Epoch: 125. Tra Loss: 0.1203. Val Loss: 0.2019. Syn Loss: 0.1206\n",
      "Model saved at the end of epoch 125.\n",
      "Epoch: 126. Tra Loss: 0.1199. Val Loss: 0.2048. Syn Loss: 0.1304\n",
      "Model saved at the end of epoch 126.\n",
      "Epoch: 127. Tra Loss: 0.1196. Val Loss: 0.2033. Syn Loss: 0.1230\n",
      "Model saved at the end of epoch 127.\n",
      "Epoch: 128. Tra Loss: 0.1193. Val Loss: 0.2041. Syn Loss: 0.1190\n",
      "Model saved at the end of epoch 128.\n",
      "Epoch: 129. Tra Loss: 0.1189. Val Loss: 0.2052. Syn Loss: 0.1218\n",
      "Model saved at the end of epoch 129.\n",
      "Epoch: 130. Tra Loss: 0.1189. Val Loss: 0.2067. Syn Loss: 0.1240\n",
      "Model saved at the end of epoch 130.\n",
      "Epoch: 131. Tra Loss: 0.1189. Val Loss: 0.2041. Syn Loss: 0.1185\n",
      "Model saved at the end of epoch 131.\n",
      "Epoch: 132. Tra Loss: 0.1187. Val Loss: 0.2058. Syn Loss: 0.1213\n",
      "Model saved at the end of epoch 132.\n",
      "Epoch: 133. Tra Loss: 0.1186. Val Loss: 0.2041. Syn Loss: 0.1183\n",
      "Model saved at the end of epoch 133.\n",
      "Epoch: 134. Tra Loss: 0.1178. Val Loss: 0.2050. Syn Loss: 0.1207\n",
      "Model saved at the end of epoch 134.\n",
      "Epoch: 135. Tra Loss: 0.1174. Val Loss: 0.2059. Syn Loss: 0.1246\n",
      "Model saved at the end of epoch 135.\n",
      "Epoch: 136. Tra Loss: 0.1168. Val Loss: 0.2056. Syn Loss: 0.1232\n",
      "Model saved at the end of epoch 136.\n",
      "Epoch: 137. Tra Loss: 0.1161. Val Loss: 0.2058. Syn Loss: 0.1230\n",
      "Model saved at the end of epoch 137.\n",
      "Epoch: 138. Tra Loss: 0.1155. Val Loss: 0.2072. Syn Loss: 0.1239\n",
      "Model saved at the end of epoch 138.\n",
      "Epoch: 139. Tra Loss: 0.1151. Val Loss: 0.2042. Syn Loss: 0.1179\n",
      "Model saved at the end of epoch 139.\n",
      "Epoch: 140. Tra Loss: 0.1146. Val Loss: 0.2044. Syn Loss: 0.1206\n",
      "Model saved at the end of epoch 140.\n",
      "Epoch: 141. Tra Loss: 0.1139. Val Loss: 0.2036. Syn Loss: 0.1179\n",
      "Model saved at the end of epoch 141.\n",
      "Epoch: 142. Tra Loss: 0.1138. Val Loss: 0.2051. Syn Loss: 0.1187\n",
      "Model saved at the end of epoch 142.\n",
      "Epoch: 143. Tra Loss: 0.1132. Val Loss: 0.2063. Syn Loss: 0.1203\n",
      "Model saved at the end of epoch 143.\n",
      "Epoch: 144. Tra Loss: 0.1134. Val Loss: 0.2062. Syn Loss: 0.1223\n",
      "Model saved at the end of epoch 144.\n",
      "Epoch: 145. Tra Loss: 0.1130. Val Loss: 0.2052. Syn Loss: 0.1193\n",
      "Model saved at the end of epoch 145.\n",
      "Epoch: 146. Tra Loss: 0.1123. Val Loss: 0.2035. Syn Loss: 0.1174\n",
      "Model saved at the end of epoch 146.\n",
      "Epoch: 147. Tra Loss: 0.1122. Val Loss: 0.2041. Syn Loss: 0.1155\n",
      "Model saved at the end of epoch 147.\n",
      "Epoch: 148. Tra Loss: 0.1121. Val Loss: 0.2075. Syn Loss: 0.1219\n",
      "Model saved at the end of epoch 148.\n",
      "Epoch: 149. Tra Loss: 0.1116. Val Loss: 0.2057. Syn Loss: 0.1199\n",
      "Model saved at the end of epoch 149.\n",
      "Epoch: 150. Tra Loss: 0.1113. Val Loss: 0.2053. Syn Loss: 0.1228\n",
      "Model saved at the end of epoch 150.\n",
      "Epoch: 151. Tra Loss: 0.1113. Val Loss: 0.2054. Syn Loss: 0.1151\n",
      "Model saved at the end of epoch 151.\n",
      "Epoch: 152. Tra Loss: 0.1107. Val Loss: 0.2066. Syn Loss: 0.1190\n",
      "Model saved at the end of epoch 152.\n",
      "Epoch: 153. Tra Loss: 0.1101. Val Loss: 0.2073. Syn Loss: 0.1206\n",
      "Model saved at the end of epoch 153.\n",
      "Epoch: 154. Tra Loss: 0.1100. Val Loss: 0.2068. Syn Loss: 0.1169\n",
      "Model saved at the end of epoch 154.\n",
      "Epoch: 155. Tra Loss: 0.1101. Val Loss: 0.2050. Syn Loss: 0.1103\n",
      "Model saved at the end of epoch 155.\n",
      "Epoch: 156. Tra Loss: 0.1097. Val Loss: 0.2068. Syn Loss: 0.1205\n",
      "Model saved at the end of epoch 156.\n",
      "Epoch: 157. Tra Loss: 0.1095. Val Loss: 0.2047. Syn Loss: 0.1233\n",
      "Model saved at the end of epoch 157.\n",
      "Epoch: 158. Tra Loss: 0.1091. Val Loss: 0.2060. Syn Loss: 0.1201\n",
      "Model saved at the end of epoch 158.\n",
      "Epoch: 159. Tra Loss: 0.1089. Val Loss: 0.2056. Syn Loss: 0.1211\n",
      "Model saved at the end of epoch 159.\n",
      "Epoch: 160. Tra Loss: 0.1089. Val Loss: 0.2062. Syn Loss: 0.1196\n",
      "Model saved at the end of epoch 160.\n",
      "Epoch: 161. Tra Loss: 0.1085. Val Loss: 0.2095. Syn Loss: 0.1241\n",
      "Model saved at the end of epoch 161.\n",
      "Epoch: 162. Tra Loss: 0.1082. Val Loss: 0.2081. Syn Loss: 0.1222\n",
      "Model saved at the end of epoch 162.\n",
      "Epoch: 163. Tra Loss: 0.1082. Val Loss: 0.2094. Syn Loss: 0.1225\n",
      "Model saved at the end of epoch 163.\n",
      "Epoch: 164. Tra Loss: 0.1076. Val Loss: 0.2078. Syn Loss: 0.1258\n",
      "Model saved at the end of epoch 164.\n",
      "Epoch: 165. Tra Loss: 0.1074. Val Loss: 0.2078. Syn Loss: 0.1205\n",
      "Model saved at the end of epoch 165.\n",
      "Epoch: 166. Tra Loss: 0.1072. Val Loss: 0.2094. Syn Loss: 0.1295\n",
      "Model saved at the end of epoch 166.\n",
      "Epoch: 167. Tra Loss: 0.1071. Val Loss: 0.2116. Syn Loss: 0.1255\n",
      "Model saved at the end of epoch 167.\n",
      "Epoch: 168. Tra Loss: 0.1066. Val Loss: 0.2105. Syn Loss: 0.1257\n",
      "Model saved at the end of epoch 168.\n",
      "Epoch: 169. Tra Loss: 0.1064. Val Loss: 0.2102. Syn Loss: 0.1235\n",
      "Model saved at the end of epoch 169.\n",
      "Epoch: 170. Tra Loss: 0.1059. Val Loss: 0.2092. Syn Loss: 0.1229\n",
      "Model saved at the end of epoch 170.\n",
      "Epoch: 171. Tra Loss: 0.1056. Val Loss: 0.2084. Syn Loss: 0.1219\n",
      "Model saved at the end of epoch 171.\n",
      "Epoch: 172. Tra Loss: 0.1054. Val Loss: 0.2081. Syn Loss: 0.1174\n",
      "Model saved at the end of epoch 172.\n",
      "Epoch: 173. Tra Loss: 0.1051. Val Loss: 0.2107. Syn Loss: 0.1199\n",
      "Model saved at the end of epoch 173.\n",
      "Epoch: 174. Tra Loss: 0.1051. Val Loss: 0.2079. Syn Loss: 0.1247\n",
      "Model saved at the end of epoch 174.\n",
      "Epoch: 175. Tra Loss: 0.1046. Val Loss: 0.2094. Syn Loss: 0.1227\n",
      "Model saved at the end of epoch 175.\n",
      "Epoch: 176. Tra Loss: 0.1047. Val Loss: 0.2136. Syn Loss: 0.1264\n",
      "Model saved at the end of epoch 176.\n",
      "Epoch: 177. Tra Loss: 0.1046. Val Loss: 0.2124. Syn Loss: 0.1277\n",
      "Model saved at the end of epoch 177.\n",
      "Epoch: 178. Tra Loss: 0.1043. Val Loss: 0.2111. Syn Loss: 0.1287\n",
      "Model saved at the end of epoch 178.\n",
      "Epoch: 179. Tra Loss: 0.1039. Val Loss: 0.2116. Syn Loss: 0.1309\n",
      "Model saved at the end of epoch 179.\n",
      "Epoch: 180. Tra Loss: 0.1035. Val Loss: 0.2139. Syn Loss: 0.1323\n",
      "Model saved at the end of epoch 180.\n",
      "Epoch: 181. Tra Loss: 0.1031. Val Loss: 0.2143. Syn Loss: 0.1254\n",
      "Training completed in 11354.14 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "mean_tra_losses = []\n",
    "mean_val_losses = []\n",
    "mean_syn_losses = []\n",
    "val_data = []\n",
    "syn_data = []\n",
    "\n",
    "start = time.time()\n",
    "epoch = 0\n",
    "while epoch <= epochs:\n",
    "    tra_losses = []\n",
    "    val_losses = []\n",
    "    syn_losses = []\n",
    "    model.train()\n",
    "    \n",
    "    # Training loop\n",
    "    for images, masks in tra_loader:\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = my_loss(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tra_losses.append(loss.data)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Validation loop\n",
    "    for images, masks in val_loader:\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            val_loss = my_loss(outputs, masks)\n",
    "            val_losses.append(val_loss.data)\n",
    "            if (epoch > patience and abs(mean_val_losses[-patience] - mean_val_losses[-1]) < threshold) or epoch == epochs:\n",
    "                val_data.extend([[outputs, masks, images]])\n",
    "\n",
    "    # Synthesis loop\n",
    "    for images, masks in syn_loader:\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            syn_loss = my_loss(outputs, masks)\n",
    "            syn_losses.append(syn_loss.data)\n",
    "            if (epoch > patience and abs(mean_val_losses[-patience] - mean_val_losses[-1]) < threshold) or epoch == epochs:\n",
    "                syn_data.extend([[outputs, masks, images]])\n",
    "\n",
    "   \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'epoch_model_vignn.pth')  # Save at the end of every epoch\n",
    "    print(f\"Model saved at the end of epoch {epoch}.\")\n",
    "    \n",
    "    # Update losses and print progress\n",
    "    epoch += 1\n",
    "    mean_tra_losses.append(torch.mean(torch.stack(tra_losses)))\n",
    "    mean_val_losses.append(torch.mean(torch.stack(val_losses)))\n",
    "    mean_syn_losses.append(torch.mean(torch.stack(syn_losses)))\n",
    "    print(f'Epoch: {epoch}. Tra Loss: {torch.mean(torch.stack(tra_losses)):.4f}. Val Loss: {torch.mean(torch.stack(val_losses)):.4f}. Syn Loss: {torch.mean(torch.stack(syn_losses)):.4f}')\n",
    "\n",
    "end = time.time()\n",
    "run_time = end - start\n",
    "print(f\"Training completed in {run_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_File = './epoch_model_vignn.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Loads trained weights and evaluates performance on irregular(Val)/irregular(Syn) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_data = []\n",
    "syn_data = []\n",
    "model.load_state_dict(torch.load(model_File),strict=False)\n",
    "model.eval()\n",
    "for images, masks in val_loader:\n",
    "    with torch.no_grad():\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        outputs = model(images)\n",
    "        val_data.extend([[outputs, masks, images]])\n",
    "\n",
    "for images, masks in syn_loader:\n",
    "    with torch.no_grad():\n",
    "        images = Variable(images.cuda())\n",
    "        masks = Variable(masks.cuda())\n",
    "        outputs = model(images)\n",
    "        syn_data.extend([[outputs, masks, images]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_truth = []\n",
    "val_predict = []\n",
    "val_truth_d = []\n",
    "for p, q in enumerate(val_data):\n",
    "    for i, j in enumerate(q[1]):\n",
    "        val_truth.append(j.reshape(1, 16384)[0].cpu().numpy())\n",
    "    for i, j in enumerate(q[0]):\n",
    "        val_predict.append(j.reshape(1, 16384)[0].cpu().numpy())\n",
    "    for i, j in enumerate(q[2]):\n",
    "        val_truth_d.append(j.reshape(1, 1024)[0].cpu().numpy())\n",
    "\n",
    "# syn_data = np.array(syn_data)\n",
    "syn_truth = []\n",
    "syn_predict = []\n",
    "syn_truth_d = []\n",
    "for p, q in enumerate(syn_data):\n",
    "    for i, j in enumerate(q[1]):\n",
    "        syn_truth.append(j.reshape(1, 16384)[0].cpu().numpy())\n",
    "    for i, j in enumerate(q[0]):\n",
    "        syn_predict.append(j.reshape(1, 16384)[0].cpu().numpy())\n",
    "    for i, j in enumerate(q[2]):\n",
    "        syn_truth_d.append(j.reshape(1, 1024)[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384,)\n",
      "(16384,)\n",
      "(1024,)\n",
      "(16384,)\n",
      "(16384,)\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "print(val_truth[0].shape)\n",
    "print(val_predict[0].shape)\n",
    "print(val_truth_d[0].shape)\n",
    "\n",
    "print(syn_truth[0].shape)\n",
    "print(syn_predict[0].shape)\n",
    "print(syn_truth_d[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E  : Reconstruction error (relative L2 norm error)\n",
    "### R2 : Coefficient of determination between true and inverted gravity anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rel = []\n",
    "val_R_2 = []\n",
    "syn_rel = []\n",
    "syn_R_2 = []\n",
    "for i in range(len(val_x)):\n",
    "    val_rel.append(np.linalg.norm(np.array(val_predict[i]) - np.array(val_truth[i]), 2)/np.linalg.norm(np.array(val_truth[i]), 2))\n",
    "    tru_d = val_truth_d[i].reshape(1024, 1)\n",
    "    pre_d = np.asmatrix(G)*np.asmatrix(density*val_predict[i].reshape(16384, 1))\n",
    "    val_R_2.append(1- np.sum(np.power(tru_d - pre_d, 2))/np.sum(np.power(tru_d - np.mean(tru_d), 2)))\n",
    "\n",
    "E = [np.array(val_rel).mean()]\n",
    "R_2 = [np.array(val_R_2).mean()]\n",
    "\n",
    "for i in range(len(syn_x)):\n",
    "    syn_rel.append(np.linalg.norm(np.array(syn_predict[i]) - np.array(syn_truth[i]), 2)/np.linalg.norm(np.array(syn_truth[i]), 2))\n",
    "    tru_d = syn_truth_d[i].reshape(1024, 1)\n",
    "    pre_d = np.asmatrix(G)*np.asmatrix(density*syn_predict[i].reshape(16384, 1))\n",
    "    syn_R_2.append(1 - np.sum(np.power(tru_d - pre_d, 2))/np.sum(np.power(tru_d - np.mean(tru_d), 2)))\n",
    "\n",
    "for i in range(category):\n",
    "    E.append(np.array(syn_rel)[part_num*i: part_num*(i+1)].mean())\n",
    "    R_2.append(np.array(syn_R_2)[part_num*i: part_num*(i+1)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9493444714655489,\n",
       " 0.9882743511133595,\n",
       " 0.9759503571840469,\n",
       " 0.9941907256410922,\n",
       " 0.9957199012886849,\n",
       " 0.9757881334668491,\n",
       " 0.9818586809886619]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62107676,\n",
       " 0.34817582,\n",
       " 0.42081055,\n",
       " 0.5918148,\n",
       " 0.5341699,\n",
       " 0.3938236,\n",
       " 0.5165317]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
